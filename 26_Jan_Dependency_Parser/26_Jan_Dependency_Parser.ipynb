{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deer fellow inspirator.\n",
    "\n",
    "Do not forget to follow me on github na ja ;)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries / Prepare function and Neural Network (Using Code from the class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import neccessary libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm  #gimmick for progressbar when you train\n",
    "import pickle #saving and loading models\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basically, it takes the current state of the buffer, stack, dependencies\n",
    "#tell us how SHIFT, LA, RA changes these three objects\n",
    "\n",
    "class Parsing(object):\n",
    "    \n",
    "    #init stack, buffer, dep\n",
    "    def __init__(self, sentence):  \n",
    "        self.sentence = sentence     #['The', 'cat', 'sat]  #conll format which is already in the tokenized form\n",
    "        self.stack    = ['ROOT']\n",
    "        self.buffer   = sentence[:]  #in the beginning, everything is inside the buffer\n",
    "        self.dep      = []           #maintains a list of tuples of dep\n",
    "    \n",
    "    #parse function that tells me how shift, la, ra changes these three objects\n",
    "    def parse_step(self, transition):     #transition could be either S, LA, RA\n",
    "        if transition == 'S':\n",
    "            #get the top guy in the buffer and put in stack\n",
    "            head = self.buffer.pop(0)\n",
    "            self.stack.append(head)\n",
    "        elif transition == 'LA':  #stack = [ROOT, He, has] ==> append to dep (has, he) and then He is gone from the stack [ROOT, has]\n",
    "            dependent = self.stack.pop(-2)  #He\n",
    "            self.dep.append((self.stack[-1], dependent))  #(has, he)\n",
    "        elif transition == 'RA':\n",
    "            #can you guys try to this???\n",
    "            dependent = self.stack.pop()  #stack = [ROOT, has, control] ==> dep (has, control), control will be gone fromt he stack [ROOT, has]\n",
    "            self.dep.append((self.stack[-1], dependent))\n",
    "        else:\n",
    "            print(f\"Bad transition: {transition}\")\n",
    "    \n",
    "    #given some series of transition, it gonna for-loop the parse function\n",
    "    def parse(self, transitions):\n",
    "        for t in transitions:\n",
    "            self.parse_step(t)\n",
    "        return self.dep\n",
    "    \n",
    "    #check whether things are finished - no need to do anymore functions....\n",
    "    def is_completed(self):\n",
    "        return (len(self.buffer) == 0) and (len(self.stack) == 1)  #so buffer is empty and ROOT is the only guy in stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch_parse(sentences, model, batch_size):\n",
    "    dep = []  #all the resulting dep\n",
    "    \n",
    "    #init Parsing instance for each sentence in the batch\n",
    "    partial_parses = [Parsing(sentence) for sentence in sentences]  #in tokenized form\n",
    "    #Parsing(['The', 'cat', 'sat']), Parsing(['Chaky', 'is', 'mad'])\n",
    "    \n",
    "    unfinished_parses = partial_parses[:]\n",
    "    \n",
    "    #while we still have sentence\n",
    "    while unfinished_parses:  #if there are still a Parsing object\n",
    "    \n",
    "        #take a certain batch of sentence\n",
    "        minibatch = unfinished_parses[:batch_size] #number of Parsing object\n",
    "        \n",
    "        #create a dummy model to tell us what's the next transition for each sentence\n",
    "        transitions = model.predict(minibatch) \n",
    "        #transitions = [S, S, .....]\n",
    "        #minibatch   = [Parsing(sentence1), Parsing(sentence2)]\n",
    "        \n",
    "                \n",
    "        # for transition predicted this dummy model\n",
    "        for transition, partial_parse in zip(transitions, minibatch):\n",
    "            #parse step\n",
    "            #transition: S\n",
    "            #partial_parse: Parsing(sentence)\n",
    "            partial_parse.parse_step(transition)\n",
    "            \n",
    "        #remove any sentence is finish\n",
    "        unfinished_parses[:] = [p for p in unfinished_parses if not p.is_completed()]\n",
    "    \n",
    "    dep = [parse.dep for parse in partial_parses]\n",
    "    \n",
    "    return dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conll(filename):\n",
    "    \n",
    "    examples = []\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        i = 0\n",
    "        word, pos, head, dep = [], [], [], []\n",
    "        for line in f.readlines():\n",
    "            i = i+1\n",
    "            wa = line.strip().split('\\t')  #['1', 'In', '_', 'ADP', 'IN', '_', '5', 'case', '_', '_']\n",
    "            #In <--------  5th guy\n",
    "            #     case\n",
    "            \n",
    "            if len(wa) == 10:  #if all the columns are there\n",
    "                word.append(wa[1].lower())\n",
    "                pos.append(wa[4])\n",
    "                head.append(int(wa[6]))\n",
    "                dep.append(wa[7])\n",
    "            \n",
    "            #the row is not exactly 10, it means new sentence\n",
    "            elif len(word) > 0:  #if there is somethign inside the word\n",
    "                examples.append({'word': word, 'pos': pos, 'head': head, 'dep': dep})  #in the sentence level\n",
    "                word, pos, head, dep = [], [], [], [] #clear word, pos, head, dep\n",
    "        \n",
    "        if len(word) > 0:  #if there is somethign inside the word\n",
    "            examples.append({'word': word, 'pos': pos, 'head': head, 'dep': dep})  #in the sentence level\n",
    "\n",
    "    return examples                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    print(\"1. Loading data\")\n",
    "    train_set = read_conll(\"/root/projects/NLP/Assignment/26_Jan_Depedency_Parser/Penn_TreeBank_ConLL/train.conll\")\n",
    "    dev_set   = read_conll(\"/root/projects/NLP/Assignment/26_Jan_Depedency_Parser/Penn_TreeBank_ConLL/dev.conll\")\n",
    "    test_set   = read_conll(\"/root/projects/NLP/Assignment/26_Jan_Depedency_Parser/Penn_TreeBank_ConLL/test.conll\")\n",
    "    \n",
    "    #make my dataset smaller because my mac cannot handle it\n",
    "    train_set = train_set[:1000]\n",
    "    dev_set   = dev_set[:500]\n",
    "    test_set  = test_set[:500]\n",
    "    \n",
    "    return train_set, dev_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_PREFIX = '<p>:' #indicating pos tags\n",
    "D_PREFIX = '<d>:' #indicating dependency tags\n",
    "UNK      = '<UNK>'\n",
    "NULL     = '<NULL>'\n",
    "ROOT     = '<ROOT>'\n",
    "\n",
    "class Parser(object):\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        \n",
    "        #set the root dep\n",
    "        self.root_dep = 'root'\n",
    "                \n",
    "        #get all the dep of the dataset as list, e.g., ['root', 'acl', 'nmod', 'nmod:npmod']\n",
    "        all_dep = [self.root_dep] + list(set([w for ex in dataset\n",
    "                                               for w in ex['dep']\n",
    "                                               if w != self.root_dep]))\n",
    "        \n",
    "        #1. put dep into tok2id lookup table, with D_PREFIX so we know it is dependency\n",
    "        #{'D_PREFIX:root': 0, 'D_PREFIX:acl': 1, 'D_PREFIX:nmod': 2, ..., 'D_PREFIX:<NULL>': 30}\n",
    "        tok2id = {D_PREFIX + l: i for (i, l) in enumerate(all_dep)}\n",
    "        tok2id[D_PREFIX + NULL] = self.D_NULL = len(tok2id)\n",
    "        \n",
    "        #we are using \"unlabeled\" where we do not label with the dependency\n",
    "        #thus the number of dependency relation is 1\n",
    "        trans = ['L', 'R', 'S']\n",
    "        self.n_deprel = 1   #because we are not predicting the relations, we are only predicting S, L, R\n",
    "        \n",
    "        #create a simple lookup table mapping action and id\n",
    "        #e.g., tran2id: {'L': 0, 'R': 1, 'S': 2}\n",
    "        #e.g., id2tran: {0: 'L', 1: 'R', 2: 'S'}\n",
    "        self.n_trans = len(trans)\n",
    "        self.tran2id = {t: i for (i, t) in enumerate(trans)}  #use for easy coding\n",
    "        self.id2tran = {i: t for (i, t) in enumerate(trans)}\n",
    "        \n",
    "        #2. put pos tags into tok2id lookup table, with P_PREFIX so we know it is pos\n",
    "        tok2id.update(build_dict([P_PREFIX + w for ex in dataset for w in ex['pos']],\n",
    "                                  offset=len(tok2id)))\n",
    "        tok2id[P_PREFIX + UNK]  = self.P_UNK  = len(tok2id)  #also remember the pos tags of unknown\n",
    "        tok2id[P_PREFIX + NULL] = self.P_NULL = len(tok2id)\n",
    "        tok2id[P_PREFIX + ROOT] = self.P_ROOT = len(tok2id)\n",
    "        \n",
    "        #now tok2id:  {'P_PREFIX:root': 0, 'P_PREFIX:acl': 1, ..., 'P_PREFIX:JJR': 62, 'P_PREFIX:<UNK>': 63, 'P_PREFIX:<NULL>': 64, 'P_PREFIX:<ROOT>': 65}\n",
    "        \n",
    "        #3. put word into tok2id lookup table\n",
    "        tok2id.update(build_dict([w for ex in dataset for w in ex['word']],\n",
    "                                  offset=len(tok2id)))\n",
    "        tok2id[UNK]  = self.UNK = len(tok2id)\n",
    "        tok2id[NULL] = self.NULL = len(tok2id)\n",
    "        tok2id[ROOT] = self.ROOT = len(tok2id)\n",
    "        \n",
    "        #now tok2id: {'D_PREFIX:root': 0, 'D_PREFIX:acl': 1, 'D_PREFIX:nmod': 2, ..., 'memory': 340, 'mr.': 341, '<UNK>': 342, '<NULL>': 343, '<ROOT>': 344}\n",
    "        \n",
    "        #create id2tok\n",
    "        self.tok2id = tok2id\n",
    "        self.id2tok = {v: k for (k, v) in tok2id.items()}\n",
    "        \n",
    "        self.n_features = 18 + 18 + 12\n",
    "        self.n_tokens = len(tok2id)\n",
    "        \n",
    "    #utility function, in case we want to convert token to id\n",
    "    #function to turn train set with words to train set with id instead using tok2id\n",
    "    def numericalize(self, examples):\n",
    "        numer_examples = []\n",
    "        for ex in examples:\n",
    "            word = [self.ROOT] + [self.tok2id[w] if w in self.tok2id\n",
    "                                  else self.UNK for w in ex['word']]\n",
    "            pos  = [self.P_ROOT] + [self.tok2id[P_PREFIX + w] if P_PREFIX + w in self.tok2id\n",
    "                                   else self.P_UNK for w in ex['pos']]\n",
    "            head = [-1] + ex['head']\n",
    "            dep  = [-1] + [self.tok2id[D_PREFIX + w] if D_PREFIX + w in self.tok2id\n",
    "                            else -1 for w in ex['dep']]\n",
    "            numer_examples.append({'word': word, 'pos': pos,\n",
    "                                 'head': head, 'dep': dep})\n",
    "        return numer_examples\n",
    "    \n",
    "    #function to extract features to form a feature embedding matrix\n",
    "    def extract_features(self, stack, buf, arcs, ex):\n",
    "             \n",
    "        #ex['word']:  [55, 32, 33, 34, 35, 30], i.e., ['root', 'ms.', 'haag', 'plays', 'elianti', '.']\n",
    "        #ex['pos']:   [29, 14, 14, 16, 14, 17], i.e., ['NNP', 'NNP', 'VBZ', 'NNP', '.']\n",
    "        #ex['head']:  [-1, 2, 3, 0, 3, 3]  or ['root', 'compound', 'nsubj', 'root', 'dobj', 'punct']}\n",
    "        #ex['dep']:   [-1, 1, 2, 0, 6, 12] or ['compound', 'nsubj', 'root', 'dobj', 'punct']\n",
    "\n",
    "        #stack     :  [0]\n",
    "        #buffer    :  [1, 2, 3, 4, 5]\n",
    "        \n",
    "        if stack[0] == \"ROOT\":\n",
    "            stack[0] = 0  #start the stack with [ROOT]\n",
    "            \n",
    "        p_features = [] #pos features (2a, 2b, 2c) - 18\n",
    "        d_features = [] #dep features (3b, 3c) - 12\n",
    "        \n",
    "        #last 3 things on the stack as features\n",
    "        #if the stack is less than 3, then we simply append NULL from the left\n",
    "        features = [self.NULL] * (3 - len(stack)) + [ex['word'][x] for x in stack[-3:]]\n",
    "        \n",
    "        # next 3 things on the buffer as features\n",
    "        #if the buffer is less than 3, simply append NULL\n",
    "        #the reason why NULL is appended on end because buffer is read left to right\n",
    "        features += [ex['word'][x] for x in buf[:3]] + [self.NULL] * (3 - len(buf))\n",
    "        \n",
    "        #corresponding pos tags\n",
    "        p_features = [self.P_NULL] * (3 - len(stack)) + [ex['pos'][x] for x in stack[-3:]]\n",
    "        p_features += [ex['pos'][x] for x in buf[:3]] + [self.P_NULL] * (3 - len(buf))\n",
    "        \n",
    "        #get leftmost children based on the dependency arcs\n",
    "        def get_lc(k):\n",
    "            return sorted([arc[1] for arc in arcs if arc[0] == k and arc[1] < k])\n",
    "\n",
    "        #get right most children based on the dependency arcs\n",
    "        def get_rc(k):\n",
    "            return sorted([arc[1] for arc in arcs if arc[0] == k and arc[1] > k],\n",
    "                          reverse=True)\n",
    "        \n",
    "        #get the leftmost and rightmost children of the top two words, thus we loop 2 times\n",
    "        for i in range(2):\n",
    "            if i < len(stack):\n",
    "                k = stack[-i-1] #-1, -2 last two in the stack\n",
    "                \n",
    "                #the first and second lefmost/rightmost children of the top two words (i=1, 2) on the stack\n",
    "                lc = get_lc(k)  \n",
    "                rc = get_rc(k)\n",
    "                \n",
    "                #the leftmost of leftmost/rightmost of rightmost children of the top two words on the stack:\n",
    "                llc = get_lc(lc[0]) if len(lc) > 0 else []\n",
    "                rrc = get_rc(rc[0]) if len(rc) > 0 else []\n",
    "\n",
    "                #(leftmost of first word on stack, rightmost of first word, \n",
    "                # leftmost of the second word on stack, rightmost of second, \n",
    "                # leftmost of leftmost, rightmost of rightmost\n",
    "                features.append(ex['word'][lc[0]] if len(lc) > 0 else self.NULL)\n",
    "                features.append(ex['word'][rc[0]] if len(rc) > 0 else self.NULL)\n",
    "                features.append(ex['word'][lc[1]] if len(lc) > 1 else self.NULL)\n",
    "                features.append(ex['word'][rc[1]] if len(rc) > 1 else self.NULL)\n",
    "                features.append(ex['word'][llc[0]] if len(llc) > 0 else self.NULL)\n",
    "                features.append(ex['word'][rrc[0]] if len(rrc) > 0 else self.NULL)\n",
    "\n",
    "                #corresponding pos\n",
    "                p_features.append(ex['pos'][lc[0]] if len(lc) > 0 else self.P_NULL)\n",
    "                p_features.append(ex['pos'][rc[0]] if len(rc) > 0 else self.P_NULL)\n",
    "                p_features.append(ex['pos'][lc[1]] if len(lc) > 1 else self.P_NULL)\n",
    "                p_features.append(ex['pos'][rc[1]] if len(rc) > 1 else self.P_NULL)\n",
    "                p_features.append(ex['pos'][llc[0]] if len(llc) > 0 else self.P_NULL)\n",
    "                p_features.append(ex['pos'][rrc[0]] if len(rrc) > 0 else self.P_NULL)\n",
    "            \n",
    "                #corresponding dep\n",
    "                d_features.append(ex['dep'][lc[0]] if len(lc) > 0 else self.D_NULL)\n",
    "                d_features.append(ex['dep'][rc[0]] if len(rc) > 0 else self.D_NULL)\n",
    "                d_features.append(ex['dep'][lc[1]] if len(lc) > 1 else self.D_NULL)\n",
    "                d_features.append(ex['dep'][rc[1]] if len(rc) > 1 else self.D_NULL)\n",
    "                d_features.append(ex['dep'][llc[0]] if len(llc) > 0 else self.D_NULL)\n",
    "                d_features.append(ex['dep'][rrc[0]] if len(rrc) > 0 else self.D_NULL)\n",
    "                \n",
    "            else:\n",
    "                #attach NULL when they don't exist\n",
    "                features += [self.NULL] * 6\n",
    "                p_features += [self.P_NULL] * 6\n",
    "                d_features += [self.D_NULL] * 6\n",
    "                \n",
    "        features += p_features + d_features\n",
    "        assert len(features) == self.n_features  #assert they are 18 + 18 + 12\n",
    "        \n",
    "        return features\n",
    "\n",
    "    #generate training examples\n",
    "    #from the training sentences and their gold parse trees \n",
    "    def create_instances(self, examples):  #examples = word, pos, head, dep\n",
    "        all_instances = []\n",
    "        \n",
    "        for i, ex in enumerate(examples):\n",
    "            #Ms. Haag plays Elianti .\n",
    "            #e.g., ex['word]: [344, 163, 99, 164, 165, 68]\n",
    "            #here 344 stands for ROOT\n",
    "            #Chaky - I cheated and take a look\n",
    "            n_words = len(ex['word']) - 1  #excluding the root\n",
    "            \n",
    "            #arcs = {(head, tail, dependency label)}\n",
    "            stack = [0]\n",
    "            buf = [i + 1 for i in range(n_words)]  #[1, 2, 3, 4, 5]\n",
    "            arcs = []\n",
    "            instances = []\n",
    "            \n",
    "            #because that's the maximum number of shift, leftarcs, rightarcs you can have\n",
    "            #this will determine the sample size of each training example\n",
    "            #if given five words, we will get a sample of (10, 48) where 10 comes from 5 * 2, and 48 is n_features\n",
    "            #but this for loop can be break if there is nothing left....\n",
    "            for i in range(n_words * 2):  #maximum times you can do either S, L, R\n",
    "                \n",
    "                #get the gold transition based on the parse trees\n",
    "                #gold_t can be either shift(2), leftarc(0), or rightarc(1)\n",
    "                gold_t = self.get_oracle(stack, buf, ex)\n",
    "                \n",
    "                #if gold_t is None, no need to extract features.....\n",
    "                if gold_t is None:\n",
    "                    break\n",
    "                \n",
    "                #make sure when the model predicts, we inform the current state of stack and buffer, so\n",
    "                #the model is not allowed to make any illegal action, e.g., buffer is empty but trying to pop\n",
    "                legal_labels = self.legal_labels(stack, buf)                \n",
    "                assert legal_labels[gold_t] == 1\n",
    "                \n",
    "                #extract all the 48 features \n",
    "                features = self.extract_features(stack, buf, arcs, ex)\n",
    "                instances.append((features, legal_labels, gold_t))\n",
    "                \n",
    "                #shift \n",
    "                if gold_t == 2:\n",
    "                    stack.append(buf[0])\n",
    "                    buf = buf[1:]\n",
    "                #left arc \n",
    "                elif gold_t == 0:\n",
    "                    arcs.append((stack[-1], stack[-2], gold_t))\n",
    "                    stack = stack[:-2] + [stack[-1]]\n",
    "                #right arc\n",
    "                else:\n",
    "                    arcs.append((stack[-2], stack[-1], gold_t - self.n_deprel))\n",
    "                    stack = stack[:-1]\n",
    "                    \n",
    "            else:\n",
    "                all_instances += instances\n",
    "\n",
    "        return all_instances\n",
    "    \n",
    "    #provide an one hot encoding of the labels\n",
    "    def legal_labels(self, stack, buf):\n",
    "        labels =  ([1] if len(stack) > 2  else [0]) * self.n_deprel  #left arc but you cannot do ROOT <--- He\n",
    "        labels += ([1] if len(stack) >= 2 else [0]) * self.n_deprel  #right arc because ROOT --> He\n",
    "        labels += [1] if len(buf) > 0 else [0]  #shift\n",
    "        return labels\n",
    "    \n",
    "    #a simple function to check punctuation POS tags\n",
    "    def punct(self, pos):\n",
    "        return pos in [\"''\", \",\", \".\", \":\", \"``\", \"-LRB-\", \"-RRB-\"]\n",
    "    \n",
    "    #decide whether to shift, leftarc, or rightarc, based on gold parse trees\n",
    "    #this is needed to create training examples which contain samples and ground truth\n",
    "    def get_oracle(self, stack, buf, ex):\n",
    "        \n",
    "        #leave if the stack is only 1, thus nothing to predict....\n",
    "        if len(stack) < 2:\n",
    "            return self.n_trans - 1\n",
    "        \n",
    "        #predict based on the last two words on the stack\n",
    "        #stack: [ROOT, he, has]\n",
    "        i0 = stack[-1] #has\n",
    "        i1 = stack[-2] #he\n",
    "        \n",
    "        #get the head and dependency\n",
    "        h0 = ex['head'][i0]\n",
    "        h1 = ex['head'][i1]\n",
    "        d0 = ex['dep'][i0]\n",
    "        d1 = ex['dep'][i1]\n",
    "        \n",
    "        #either shift, left arc or right arc\n",
    "        #\"Shift\" = 2; \"LA\" = 0; \"RA\" = 1\n",
    "        #if head of the second last word is the last word, then leftarc\n",
    "        if (i1 > 0) and (h1 == i0):\n",
    "            return 0  #action is left arc ---> gold_t\n",
    "        #if head of the last word is the second last word, then rightarc\n",
    "        #make sure nothing in the buffer has head with the last word on the stack\n",
    "        #otherwise, we lose the last word.....\n",
    "        elif (i1 >= 0) and (h0 == i1) and \\\n",
    "                (not any([x for x in buf if ex['head'][x] == i0])):\n",
    "            return 1  #right arc\n",
    "        #otherwise shift, if something is left in buffer, otherwise, do nothing....\n",
    "        else:\n",
    "            return None if len(buf) == 0 else 2  #shift\n",
    "        \n",
    "    def parse(self, dataset, eval_batch_size=5000):\n",
    "        sentences = []\n",
    "        sentence_id_to_idx = {}\n",
    "        \n",
    "        for i, example in enumerate(dataset):\n",
    "            \n",
    "            #example['word']=[188, 186, 186, ..., 59]\n",
    "            #n_words=37\n",
    "            #sentence=[1, 2, 3, 4, 5,.., 37]\n",
    "            \n",
    "            n_words = len(example['word']) - 1\n",
    "            sentence = [j + 1 for j in range(n_words)]            \n",
    "            sentences.append(sentence)\n",
    "            \n",
    "            #mapping the object unique id to the i            \n",
    "            #The id is the object's memory address\n",
    "            sentence_id_to_idx[id(sentence)] = i\n",
    "            \n",
    "        model = ModelWrapper(self, dataset, sentence_id_to_idx)\n",
    "        dependencies = minibatch_parse(sentences, model, eval_batch_size)\n",
    "        \n",
    "        UAS = all_tokens = 0.0\n",
    "        with tqdm(total=len(dataset)) as prog:\n",
    "            for i, ex in enumerate(dataset):\n",
    "                head = [-1] * len(ex['word'])\n",
    "                for h, t, in dependencies[i]:\n",
    "                    head[t] = h\n",
    "                for pred_h, gold_h, gold_l, pos in \\\n",
    "                        zip(head[1:], ex['head'][1:], ex['dep'][1:], ex['pos'][1:]):\n",
    "                        assert self.id2tok[pos].startswith(P_PREFIX)\n",
    "                        pos_str = self.id2tok[pos][len(P_PREFIX):]\n",
    "                        if (not self.punct(pos_str)):\n",
    "                            UAS += 1 if pred_h == gold_h else 0\n",
    "                            all_tokens += 1\n",
    "                prog.update(i + 1)\n",
    "        UAS /= all_tokens\n",
    "        return UAS, dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapper(object):\n",
    "    def __init__(self, parser, dataset, sentence_id_to_idx):\n",
    "        self.parser = parser\n",
    "        self.dataset = dataset\n",
    "        self.sentence_id_to_idx = sentence_id_to_idx\n",
    "\n",
    "    def predict(self, partial_parses):\n",
    "        mb_x = [self.parser.extract_features(p.stack, p.buffer, p.dep,\n",
    "                                             self.dataset[self.sentence_id_to_idx[id(p.sentence)]])\n",
    "                for p in partial_parses]\n",
    "        mb_x = np.array(mb_x).astype('int32')\n",
    "        mb_x = torch.from_numpy(mb_x).long()\n",
    "        mb_l = [self.parser.legal_labels(p.stack, p.buffer) for p in partial_parses]\n",
    "\n",
    "        pred = self.parser.model(mb_x)\n",
    "        pred = pred.detach().numpy()\n",
    "        \n",
    "        #we need to multiply 10000 with legal labels, to force the model not to make any impossible prediction\n",
    "        #other, when we parse sequentially, sometimes there is nothing in the buffer or stack, thus error....        \n",
    "        pred = np.argmax(pred + 10000 * np.array(mb_l).astype('float32'), 1)\n",
    "        pred = [\"S\" if p == 2 else (\"LA\" if p == 0 else \"RA\") for p in pred]\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a simple function to create ids.....\n",
    "def build_dict(keys, offset=0):\n",
    "    #keys = ['P_PREFIX:IN', 'P_PREFIX:DT', 'P_PREFIX:NNP', 'P_PREFIX:CD', so on...]\n",
    "    #offset is needed because this tok2id has something already inside....\n",
    "    count = Counter()\n",
    "    for key in keys:\n",
    "        count[key] += 1\n",
    "    \n",
    "    #most_common = [('P_PREFIX:NN', 70), ('P_PREFIX:IN', 57), ... , ('P_PREFIX:JJR', 1)]\n",
    "    #we use most_common in case we only want some maximum pos tags....\n",
    "    mc = count.most_common()\n",
    "    \n",
    "    #{'P_PREFIX:NN': 31, 'P_PREFIX:IN': 32, .., 'P_PREFIX:JJR': 62} \n",
    "    return {w[0]: index + offset for (index, w) in enumerate(mc)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatches(data, minibatch_size, shuffle=True):\n",
    "    data_size = len(data[0])\n",
    "    indices = np.arange(data_size)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "    for minibatch_start in np.arange(0, data_size, minibatch_size):\n",
    "        minibatch_indices = indices[minibatch_start:minibatch_start + minibatch_size]\n",
    "        yield [_minibatch(d, minibatch_indices) for d in data]\n",
    "\n",
    "def _minibatch(data, minibatch_idx):\n",
    "    return data[minibatch_idx] if type(data) is np.ndarray else [data[i] for i in minibatch_idx]\n",
    "\n",
    "def minibatches(data, batch_size):\n",
    "    x = np.array([d[0] for d in data])\n",
    "    y = np.array([d[2] for d in data])\n",
    "    one_hot = np.zeros((y.size, 3))\n",
    "    one_hot[np.arange(y.size), y] = 1\n",
    "    return get_minibatches([x, one_hot], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParserModel(nn.Module):\n",
    "\n",
    "    def __init__(self, embeddings, n_features=48,\n",
    "                 hidden_size=400, n_classes=3, dropout_prob=0.5):\n",
    "\n",
    "        super(ParserModel, self).__init__()\n",
    "        self.n_features   = n_features\n",
    "        self.n_classes    = n_classes\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.embed_size   = embeddings.shape[1]\n",
    "        self.hidden_size  = hidden_size\n",
    "        self.pretrained_embeddings = nn.Embedding(embeddings.shape[0], self.embed_size)\n",
    "        self.pretrained_embeddings.weight = nn.Parameter(torch.tensor(embeddings))\n",
    "\n",
    "        self.embed_to_hidden = nn.Linear(n_features * self.embed_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        self.hidden_to_logits = nn.Linear(hidden_size, n_classes)\n",
    "\n",
    "    def embedding_lookup(self, t):\n",
    "        #t:  batch_size, n_features\n",
    "        batch_size = t.size()[0]\n",
    "                    \n",
    "        x = self.pretrained_embeddings(t)        \n",
    "        x = x.reshape(-1, self.n_features * self.embed_size)\n",
    "        # x = (1024, 48 * 50)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, t):\n",
    "        # t: (1024, 48)\n",
    "        embeddings = self.embedding_lookup(t)  \n",
    "    \n",
    "        # embeddings: (1024, 48 * 50)\n",
    "        hidden = self.embed_to_hidden(embeddings)\n",
    "    \n",
    "        # hidden: (1024, 200)\n",
    "        hidden_activations = F.relu(hidden)\n",
    "        # hidden_activations: (1024, 200)\n",
    "        thin_net = self.dropout(hidden_activations)\n",
    "        # thin_net: (1024, 200)\n",
    "        logits = self.hidden_to_logits(thin_net)\n",
    "        # logits: (1024, 3)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just a class to get the average.....\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(parser, train_data, dev_data, output_path, batch_size=1024, n_epochs=10, lr=0.0005):\n",
    "    \n",
    "    best_dev_UAS = 0\n",
    "    \n",
    "    optimizer = optim.Adam(parser.model.parameters(), lr=0.001)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {:} out of {:}\".format(epoch + 1, n_epochs))\n",
    "        dev_UAS = train_for_epoch(\n",
    "            parser, train_data, dev_data, optimizer, loss_func, batch_size)\n",
    "        if dev_UAS > best_dev_UAS:\n",
    "            best_dev_UAS = dev_UAS\n",
    "            print(\"New best dev UAS! Saving model.\")\n",
    "            torch.save(parser.model.state_dict(), output_path)\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "def train_for_epoch(parser, train_data, dev_data, optimizer, loss_func, batch_size):\n",
    "    \n",
    "    parser.model.train()  # Places model in \"train\" mode, i.e. apply dropout layer\n",
    "    n_minibatches = math.ceil(len(train_data) / batch_size)\n",
    "    loss_meter = AverageMeter()\n",
    "\n",
    "    with tqdm(total=(n_minibatches)) as prog:\n",
    "        for i, (train_x, train_y) in enumerate(minibatches(train_data, batch_size)):\n",
    "            \n",
    "            #train_x:  batch_size, n_features\n",
    "            #train_y:  batch_size, target(=3)\n",
    "            \n",
    "            optimizer.zero_grad() \n",
    "            loss = 0.\n",
    "            train_x = torch.from_numpy(train_x).long()  #long() for int so embedding works....\n",
    "            train_y = torch.from_numpy(train_y.nonzero()[1]).long()  #get the index with 1 because torch expects label to be single integer\n",
    "\n",
    "            # Forward pass: compute predicted logits.\n",
    "            logits = parser.model(train_x)\n",
    "            # Compute loss\n",
    "            loss = loss_func(logits, train_y)\n",
    "            # Compute gradients of the loss w.r.t model parameters.\n",
    "            loss.backward()\n",
    "            # Take step with optimizer.\n",
    "            optimizer.step()\n",
    "\n",
    "            prog.update(1)\n",
    "            loss_meter.update(loss.item())\n",
    "\n",
    "    print(\"Average Train Loss: {}\".format(loss_meter.avg))\n",
    "    print(\"Evaluating on dev set\",)\n",
    "    parser.model.eval()  # Places model in \"eval\" mode, i.e. don't apply dropout layer\n",
    "        \n",
    "    dev_UAS, _ = parser.parse(dev_data)\n",
    "    print(\"- dev UAS: {:.2f}\".format(dev_UAS * 100.0))\n",
    "    return dev_UAS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test functions\n",
    "Basically, we tried to test that the functions that we copy from Chaky work correctly!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test ETL functions\n",
    "Some function in this module requires to change path or download some data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading data\n"
     ]
    }
   ],
   "source": [
    "# Test load_data functions\n",
    "\n",
    "train_set, dev_set, test_set = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Building parser\n",
      "took 0.06 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"2. Building parser\")\n",
    "start = time.time()\n",
    "parser = Parser(train_set)\n",
    "print(\"took {:.2f} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word:  ['ms.', 'haag', 'plays', 'elianti', '.']\n",
      "Pos:  ['NNP', 'NNP', 'VBZ', 'NNP', '.']\n",
      "Head:  [2, 3, 0, 3, 3]\n",
      "Dep:  ['compound', 'nsubj', 'root', 'dobj', 'punct']\n"
     ]
    }
   ],
   "source": [
    "#before numericalize\n",
    "print(\"Word: \", train_set[1][\"word\"])\n",
    "print(\"Pos: \",  train_set[1][\"pos\"])\n",
    "print(\"Head: \", train_set[1][\"head\"])\n",
    "print(\"Dep: \",  train_set[1][\"dep\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = parser.numericalize(train_set)\n",
    "dev_set   = parser.numericalize(dev_set)\n",
    "test_set  = parser.numericalize(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word:  [5156, 304, 1364, 1002, 2144, 87]\n",
      "Pos:  [84, 42, 42, 55, 42, 46]\n",
      "Head:  [-1, 2, 3, 0, 3, 3]\n",
      "Dep:  [-1, 1, 16, 0, 13, 27]\n"
     ]
    }
   ],
   "source": [
    "#after numericalize\n",
    "print(\"Word: \", train_set[1][\"word\"])\n",
    "print(\"Pos: \",  train_set[1][\"pos\"])\n",
    "print(\"Head: \", train_set[1][\"head\"])\n",
    "print(\"Dep: \",  train_set[1][\"dep\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Loading pretrained embeddings...\n",
      "Embedding matrix shape (vocab, emb size):  (5157, 50)\n",
      "took 4.69 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"4. Loading pretrained embeddings...\",)\n",
    "start = time.time()\n",
    "word_vectors = {}\n",
    "for line in open(\"/root/projects/NLP/Assignment/26_Jan_Depedency_Parser/en-cw.txt\").readlines():\n",
    "    we = line.strip().split() #we = word embeddings - first column: word;  the rest is embedding\n",
    "    word_vectors[we[0]] = [float(x) for x in we[1:]] #{word: [list of 50 numbers], nextword: [another list], so on...}\n",
    "    \n",
    "#create an empty embedding matrix holding the embedding lookup table (vocab size, embed dim)\n",
    "#we use random.normal instead of zeros, to keep the embedding matrix arbitrary in case word vectors don't exist....\n",
    "embeddings_matrix = np.asarray(np.random.normal(0, 0.9, (parser.n_tokens, 50)), dtype='float32')\n",
    "\n",
    "for token in parser.tok2id:\n",
    "        i = parser.tok2id[token]\n",
    "        if token in word_vectors:\n",
    "            embeddings_matrix[i] = word_vectors[token]\n",
    "        elif token.lower() in word_vectors:\n",
    "            embeddings_matrix[i] = word_vectors[token.lower()]\n",
    "print(\"Embedding matrix shape (vocab, emb size): \", embeddings_matrix.shape)\n",
    "print(\"took {:.2f} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Preprocessing training data...\n",
      "took 1.73 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"5. Preprocessing training data...\",)\n",
    "start = time.time()\n",
    "train_examples = parser.create_instances(train_set)\n",
    "print(\"took {:.2f} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5155,\n",
       "  5155,\n",
       "  5156,\n",
       "  91,\n",
       "  113,\n",
       "  806,\n",
       "  5155,\n",
       "  5155,\n",
       "  5155,\n",
       "  5155,\n",
       "  5155,\n",
       "  5155,\n",
       "  5155,\n",
       "  5155,\n",
       "  5155,\n",
       "  5155,\n",
       "  5155,\n",
       "  5155,\n",
       "  83,\n",
       "  83,\n",
       "  84,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  83,\n",
       "  83,\n",
       "  83,\n",
       "  83,\n",
       "  83,\n",
       "  83,\n",
       "  83,\n",
       "  83,\n",
       "  83,\n",
       "  83,\n",
       "  83,\n",
       "  83,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  38],\n",
       " [0, 0, 1],\n",
       " 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[0]  #features, legal_labels, transition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Training/Testing functions\n",
    "To see if it's work correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING\n",
      "================================================================================\n",
      "Epoch 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:02<00:00, 16.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.6019479172925154\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 7420008.14it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 58.61\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:02<00:00, 20.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.30606047871212166\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 7576678.44it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 65.07\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 3 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:02<00:00, 20.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.2493250866731008\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 7111058.75it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 68.02\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 4 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:02<00:00, 20.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.21460797109951577\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 7975111.97it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 69.25\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 5 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:02<00:00, 19.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.19113899674266577\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 7268076.59it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 70.44\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 6 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:02<00:00, 20.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.17049867597719034\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 5758059.69it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 72.48\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 7 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:02<00:00, 18.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.15453913155943155\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 6217957.51it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 74.24\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 8 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:02<00:00, 17.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.141439289941142\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 6949723.86it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 73.90\n",
      "\n",
      "Epoch 9 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:02<00:00, 17.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.12877158960327506\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 7499986.81it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 75.42\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 10 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:02<00:00, 18.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.11755812478562196\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 7369214.68it/s]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 75.39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#create directory if it does not exist for saving the weights...\n",
    "output_dir = \"output/{:%Y%m%d_%H%M%S}_All_features/\".format(datetime.now())\n",
    "output_path = output_dir + \"model.weights\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "print(80 * \"=\")\n",
    "print(\"TRAINING\")\n",
    "print(80 * \"=\")\n",
    "    \n",
    "model = ParserModel(embeddings_matrix)\n",
    "parser.model = model\n",
    "\n",
    "start = time.time()\n",
    "train(parser, train_examples, dev_set, output_path,\n",
    "      batch_size=1024, n_epochs=10, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TESTING\n",
      "================================================================================\n",
      "Restoring the best model weights found on the dev set\n",
      "Final evaluation on test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 6934770.12it/s]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- test UAS: 76.18\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(80 * \"=\")\n",
    "print(\"TESTING\")\n",
    "print(80 * \"=\")\n",
    "\n",
    "print(\"Restoring the best model weights found on the dev set\")\n",
    "parser.model.load_state_dict(torch.load(output_path))\n",
    "print(\"Final evaluation on test set\",)\n",
    "parser.model.eval()\n",
    "UAS, dependencies = parser.parse(test_set)\n",
    "print(\"- test UAS: {:.2f}\".format(UAS * 100.0))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation study\n",
    "\n",
    "Now, We know that the pretrained embedding with Penn Treebank dataset got UAS score of 76.57 (See section above). It time for us to investigate performance by removing some components to understand its contributions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify Parser function\n",
    "In order to archieves that we need to modify the parser code! The code above specifically design for 48 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_PREFIX = '<p>:' #indicating pos tags\n",
    "D_PREFIX = '<d>:' #indicating dependency tags\n",
    "UNK      = '<UNK>'\n",
    "NULL     = '<NULL>'\n",
    "ROOT     = '<ROOT>'\n",
    "\n",
    "class Modify_Parser(object):\n",
    "\n",
    "    def __init__(self, dataset, pos_t=True, dep_t=True):\n",
    "        \n",
    "        # We declare in this place for convenience reason, you will see why if you scroll a little.\n",
    "        self.n_features = 18\n",
    "        self.pos_t = pos_t\n",
    "        self.dep_t = dep_t\n",
    "\n",
    "        # We need this to prevent reference before assignment, so I will declare these here for convenience reason\n",
    "        tok2id = dict() \n",
    "        trans = ['L', 'R', 'S']\n",
    "        self.n_trans = len(trans)\n",
    "        self.n_deprel = 1\n",
    "        \n",
    "        # ! dep_t == False indicate that we do not want entirely of this dependency arc feature!\n",
    "        # Pay close attention to the code inside if.\n",
    "        ##################################################################################################\n",
    "        #set the root dep\n",
    "        if self.dep_t == True: # dep_t indicate that we want this feature or not\n",
    "            self.root_dep = 'root'\n",
    "                \n",
    "        #get all the dep of the dataset as list, e.g., ['root', 'acl', 'nmod', 'nmod:npmod']\n",
    "         # Basically, if it's false we ill not create this list\n",
    "            all_dep = [self.root_dep] + list(set([w for ex in dataset\n",
    "                                                for w in ex['dep']\n",
    "                                                if w != self.root_dep]))\n",
    "        \n",
    "        #1. put dep into tok2id lookup table, with D_PREFIX so we know it is dependency\n",
    "        #{'D_PREFIX:root': 0, 'D_PREFIX:acl': 1, 'D_PREFIX:nmod': 2, ..., 'D_PREFIX:<NULL>': 30}\n",
    "            tok2id = {D_PREFIX + l: i for (i, l) in enumerate(all_dep)}\n",
    "            tok2id[D_PREFIX + NULL] = self.D_NULL = len(tok2id)\n",
    "        \n",
    "        #we are using \"unlabeled\" where we do not label with the dependency\n",
    "        #thus the number of dependency relation is 1\n",
    "            trans = ['L', 'R', 'S']\n",
    "            self.n_deprel = 1   #because we are not predicting the relations, we are only predicting S, L, R\n",
    "        \n",
    "            #create a simple lookup table mapping action and id\n",
    "            #e.g., tran2id: {'L': 0, 'R': 1, 'S': 2}\n",
    "            #e.g., id2tran: {0: 'L', 1: 'R', 2: 'S'}\n",
    "            self.n_trans = len(trans)\n",
    "            self.tran2id = {t: i for (i, t) in enumerate(trans)}  #use for easy coding\n",
    "            self.id2tran = {i: t for (i, t) in enumerate(trans)}\n",
    "        #####################################################################################################\n",
    "        \n",
    "        # Same for the code above but we kind of do the samething for pos features.\n",
    "        #####################################################################################################\n",
    "        if self.pos_t == True:\n",
    "            #2. put pos tags into tok2id lookup table, with P_PREFIX so we know it is pos\n",
    "            tok2id.update(build_dict([P_PREFIX + w for ex in dataset for w in ex['pos']],\n",
    "                                    offset=len(tok2id)))\n",
    "            tok2id[P_PREFIX + UNK]  = self.P_UNK  = len(tok2id)  #also remember the pos tags of unknown\n",
    "            tok2id[P_PREFIX + NULL] = self.P_NULL = len(tok2id)\n",
    "            tok2id[P_PREFIX + ROOT] = self.P_ROOT = len(tok2id)\n",
    "            \n",
    "            #now tok2id:  {'P_PREFIX:root': 0, 'P_PREFIX:acl': 1, ..., 'P_PREFIX:JJR': 62, 'P_PREFIX:<UNK>': 63, 'P_PREFIX:<NULL>': 64, 'P_PREFIX:<ROOT>': 65}\n",
    "        \n",
    "        #3. put word into tok2id lookup table\n",
    "        tok2id.update(build_dict([w for ex in dataset for w in ex['word']],\n",
    "                                  offset=len(tok2id)))\n",
    "        tok2id[UNK]  = self.UNK = len(tok2id)\n",
    "        tok2id[NULL] = self.NULL = len(tok2id)\n",
    "        tok2id[ROOT] = self.ROOT = len(tok2id)\n",
    "        \n",
    "        #now tok2id: {'D_PREFIX:root': 0, 'D_PREFIX:acl': 1, 'D_PREFIX:nmod': 2, ..., 'memory': 340, 'mr.': 341, '<UNK>': 342, '<NULL>': 343, '<ROOT>': 344}\n",
    "        \n",
    "        #create id2tok\n",
    "        self.tok2id = tok2id\n",
    "        self.id2tok = {v: k for (k, v) in tok2id.items()}\n",
    "        \n",
    "        # If some of the feature are not use, the number of features also change, so we need to fix this!\n",
    "        if self.pos_t == True:\n",
    "            self.n_features = self.n_features + 18\n",
    "        if self.dep_t == True:\n",
    "            self.n_features = self.n_features + 12\n",
    "        \n",
    "        self.n_tokens = len(tok2id)\n",
    "        \n",
    "    #utility function, in case we want to convert token to id\n",
    "    #function to turn train set with words to train set with id instead using tok2id\n",
    "    def numericalize(self, examples):\n",
    "        numer_examples = []\n",
    "        for ex in examples:\n",
    "            word = [self.ROOT] + [self.tok2id[w] if w in self.tok2id\n",
    "                                  else self.UNK for w in ex['word']]\n",
    "            if self.pos_t == True:\n",
    "                pos  = [self.P_ROOT] + [self.tok2id[P_PREFIX + w] if P_PREFIX + w in self.tok2id\n",
    "                                    else self.P_UNK for w in ex['pos']]\n",
    "            head = [-1] + ex['head']\n",
    "            if self.dep_t == True:\n",
    "                dep  = [-1] + [self.tok2id[D_PREFIX + w] if D_PREFIX + w in self.tok2id\n",
    "                                else -1 for w in ex['dep']]\n",
    "            \n",
    "            if (self.pos_t == False) and (self.dep_t == False):\n",
    "                numer_examples.append({'word': word, 'head': head})\n",
    "\n",
    "            elif (self.pos_t == False) and (self.dep_t == True):\n",
    "                numer_examples.append({'word': word, 'head': head, 'dep': dep})\n",
    "\n",
    "            elif (self.pos_t == True) and (self.dep_t == False):\n",
    "                numer_examples.append({'word': word, 'pos': pos,\n",
    "                        'head': head})\n",
    "            else:\n",
    "                numer_examples.append({'word': word, 'pos': pos,\n",
    "                                 'head': head, 'dep': dep})\n",
    "        return numer_examples\n",
    "    \n",
    "    #function to extract features to form a feature embedding matrix\n",
    "    def extract_features(self, stack, buf, arcs, ex):\n",
    "             \n",
    "        #ex['word']:  [55, 32, 33, 34, 35, 30], i.e., ['root', 'ms.', 'haag', 'plays', 'elianti', '.']\n",
    "        #ex['pos']:   [29, 14, 14, 16, 14, 17], i.e., ['NNP', 'NNP', 'VBZ', 'NNP', '.']\n",
    "        #ex['head']:  [-1, 2, 3, 0, 3, 3]  or ['root', 'compound', 'nsubj', 'root', 'dobj', 'punct']}\n",
    "        #ex['dep']:   [-1, 1, 2, 0, 6, 12] or ['compound', 'nsubj', 'root', 'dobj', 'punct']\n",
    "\n",
    "        #stack     :  [0]\n",
    "        #buffer    :  [1, 2, 3, 4, 5]\n",
    "        \n",
    "        if stack[0] == \"ROOT\":\n",
    "            stack[0] = 0  #start the stack with [ROOT]\n",
    "        \n",
    "        p_features = [] #pos features (2a, 2b, 2c) - 18\n",
    "        d_features = [] #dep features (3b, 3c) - 12\n",
    "        \n",
    "        #last 3 things on the stack as features\n",
    "        #if the stack is less than 3, then we simply append NULL from the left\n",
    "        features = [self.NULL] * (3 - len(stack)) + [ex['word'][x] for x in stack[-3:]]\n",
    "        \n",
    "        # next 3 things on the buffer as features\n",
    "        #if the buffer is less than 3, simply append NULL\n",
    "        #the reason why NULL is appended on end because buffer is read left to right\n",
    "        features += [ex['word'][x] for x in buf[:3]] + [self.NULL] * (3 - len(buf))\n",
    "        \n",
    "        if self.pos_t == True:\n",
    "            #corresponding pos tags\n",
    "            p_features = [self.P_NULL] * (3 - len(stack)) + [ex['pos'][x] for x in stack[-3:]]\n",
    "            p_features += [ex['pos'][x] for x in buf[:3]] + [self.P_NULL] * (3 - len(buf))\n",
    "        \n",
    "        #get leftmost children based on the dependency arcs\n",
    "        def get_lc(k):\n",
    "            return sorted([arc[1] for arc in arcs if arc[0] == k and arc[1] < k])\n",
    "\n",
    "        #get right most children based on the dependency arcs\n",
    "        def get_rc(k):\n",
    "            return sorted([arc[1] for arc in arcs if arc[0] == k and arc[1] > k],\n",
    "                          reverse=True)\n",
    "\n",
    "        #get the leftmost and rightmost children of the top two words, thus we loop 2 times\n",
    "        for i in range(2):\n",
    "            if i < len(stack):\n",
    "                k = stack[-i-1] #-1, -2 last two in the stack\n",
    "                \n",
    "                #the first and second lefmost/rightmost children of the top two words (i=1, 2) on the stack\n",
    "                lc = get_lc(k)  \n",
    "                rc = get_rc(k)\n",
    "                \n",
    "                #the leftmost of leftmost/rightmost of rightmost children of the top two words on the stack:\n",
    "                llc = get_lc(lc[0]) if len(lc) > 0 else []\n",
    "                rrc = get_rc(rc[0]) if len(rc) > 0 else []\n",
    "\n",
    "                #(leftmost of first word on stack, rightmost of first word, \n",
    "                # leftmost of the second word on stack, rightmost of second, \n",
    "                # leftmost of leftmost, rightmost of rightmost\n",
    "                features.append(ex['word'][lc[0]] if len(lc) > 0 else self.NULL)\n",
    "                features.append(ex['word'][rc[0]] if len(rc) > 0 else self.NULL)\n",
    "                features.append(ex['word'][lc[1]] if len(lc) > 1 else self.NULL)\n",
    "                features.append(ex['word'][rc[1]] if len(rc) > 1 else self.NULL)\n",
    "                features.append(ex['word'][llc[0]] if len(llc) > 0 else self.NULL)\n",
    "                features.append(ex['word'][rrc[0]] if len(rrc) > 0 else self.NULL)\n",
    "\n",
    "                if self.pos_t == True:\n",
    "                    #corresponding pos\n",
    "                    p_features.append(ex['pos'][lc[0]] if len(lc) > 0 else self.P_NULL)\n",
    "                    p_features.append(ex['pos'][rc[0]] if len(rc) > 0 else self.P_NULL)\n",
    "                    p_features.append(ex['pos'][lc[1]] if len(lc) > 1 else self.P_NULL)\n",
    "                    p_features.append(ex['pos'][rc[1]] if len(rc) > 1 else self.P_NULL)\n",
    "                    p_features.append(ex['pos'][llc[0]] if len(llc) > 0 else self.P_NULL)\n",
    "                    p_features.append(ex['pos'][rrc[0]] if len(rrc) > 0 else self.P_NULL)\n",
    "\n",
    "                if self.dep_t == True:\n",
    "                    #corresponding dep\n",
    "                    d_features.append(ex['dep'][lc[0]] if len(lc) > 0 else self.D_NULL)\n",
    "                    d_features.append(ex['dep'][rc[0]] if len(rc) > 0 else self.D_NULL)\n",
    "                    d_features.append(ex['dep'][lc[1]] if len(lc) > 1 else self.D_NULL)\n",
    "                    d_features.append(ex['dep'][rc[1]] if len(rc) > 1 else self.D_NULL)\n",
    "                    d_features.append(ex['dep'][llc[0]] if len(llc) > 0 else self.D_NULL)\n",
    "                    d_features.append(ex['dep'][rrc[0]] if len(rrc) > 0 else self.D_NULL)\n",
    "                \n",
    "            else:\n",
    "                #attach NULL when they don't exist\n",
    "                features += [self.NULL] * 6\n",
    "                if self.pos_t == True:\n",
    "                    p_features += [self.P_NULL] * 6\n",
    "                if self.dep_t == True:\n",
    "                    d_features += [self.D_NULL] * 6\n",
    "\n",
    "        if (self.pos_t == True) and (self.dep_t == True):\n",
    "            features += p_features + d_features\n",
    "\n",
    "        elif (self.pos_t == False) and (self.dep_t == True):\n",
    "            features += d_features\n",
    "\n",
    "        elif (self.pos_t == True) and (self.dep_t == False):\n",
    "            features += p_features\n",
    "        \n",
    "        else:\n",
    "            features = features\n",
    "\n",
    "        assert len(features) == self.n_features  #assert they are 18 + 18 + 12\n",
    "        \n",
    "        return features\n",
    "\n",
    "    #generate training examples\n",
    "    #from the training sentences and their gold parse trees \n",
    "    def create_instances(self, examples):  #examples = word, pos, head, dep\n",
    "        all_instances = []\n",
    "        \n",
    "        for i, ex in enumerate(examples):\n",
    "            #Ms. Haag plays Elianti .\n",
    "            #e.g., ex['word]: [344, 163, 99, 164, 165, 68]\n",
    "            #here 344 stands for ROOT\n",
    "            #Chaky - I cheated and take a look\n",
    "            n_words = len(ex['word']) - 1  #excluding the root\n",
    "            \n",
    "            #arcs = {(head, tail, dependency label)}\n",
    "            stack = [0]\n",
    "            buf = [i + 1 for i in range(n_words)]  #[1, 2, 3, 4, 5]\n",
    "            arcs = []\n",
    "            instances = []\n",
    "            \n",
    "            #because that's the maximum number of shift, leftarcs, rightarcs you can have\n",
    "            #this will determine the sample size of each training example\n",
    "            #if given five words, we will get a sample of (10, 48) where 10 comes from 5 * 2, and 48 is n_features\n",
    "            #but this for loop can be break if there is nothing left....\n",
    "            \n",
    "            for i in range(n_words * 2):  #maximum times you can do either S, L, R\n",
    "                \n",
    "                #get the gold transition based on the parse trees\n",
    "                #gold_t can be either shift(2), leftarc(0), or rightarc(1)\n",
    "                gold_t = self.get_oracle(stack, buf, ex)\n",
    "                \n",
    "                #if gold_t is None, no need to extract features.....\n",
    "                if gold_t is None:\n",
    "                    break\n",
    "                \n",
    "                #make sure when the model predicts, we inform the current state of stack and buffer, so\n",
    "                #the model is not allowed to make any illegal action, e.g., buffer is empty but trying to pop\n",
    "                legal_labels = self.legal_labels(stack, buf)                \n",
    "                assert legal_labels[gold_t] == 1\n",
    "                \n",
    "                #extract the features that we want to use.\n",
    "                features = self.extract_features(stack, buf, arcs, ex)\n",
    "                instances.append((features, legal_labels, gold_t))\n",
    "                \n",
    "                #shift \n",
    "                if gold_t == 2:\n",
    "                    stack.append(buf[0])\n",
    "                    buf = buf[1:]\n",
    "                #left arc \n",
    "                elif gold_t == 0:\n",
    "                    arcs.append((stack[-1], stack[-2], gold_t))\n",
    "                    stack = stack[:-2] + [stack[-1]]\n",
    "                #right arc\n",
    "                else:\n",
    "                    arcs.append((stack[-2], stack[-1], gold_t - self.n_deprel))\n",
    "                    stack = stack[:-1]\n",
    "                    \n",
    "            else:\n",
    "                all_instances += instances\n",
    "\n",
    "        if self.dep_t == False: # We only need the word and pos\n",
    "            all_instances = [[instance[0], instance[2]] for instance in all_instances]\n",
    "\n",
    "        return all_instances\n",
    "    \n",
    "    #provide an one hot encoding of the labels\n",
    "    def legal_labels(self, stack, buf):\n",
    "        labels =  ([1] if len(stack) > 2  else [0]) * self.n_deprel  #left arc but you cannot do ROOT <--- He\n",
    "        labels += ([1] if len(stack) >= 2 else [0]) * self.n_deprel  #right arc because ROOT --> He\n",
    "        labels += [1] if len(buf) > 0 else [0]  #shift\n",
    "        return labels\n",
    "    \n",
    "    #a simple function to check punctuation POS tags\n",
    "    def punct(self, pos):\n",
    "        return pos in [\"''\", \",\", \".\", \":\", \"``\", \"-LRB-\", \"-RRB-\"]\n",
    "    \n",
    "    #decide whether to shift, leftarc, or rightarc, based on gold parse trees\n",
    "    #this is needed to create training examples which contain samples and ground truth\n",
    "    def get_oracle(self, stack, buf, ex):\n",
    "        \n",
    "        #leave if the stack is only 1, thus nothing to predict....\n",
    "        if len(stack) < 2:\n",
    "            return self.n_trans - 1\n",
    "        \n",
    "        #predict based on the last two words on the stack\n",
    "        #stack: [ROOT, he, has]\n",
    "        i0 = stack[-1] #has\n",
    "        i1 = stack[-2] #he\n",
    "        \n",
    "        #get the head and dependency\n",
    "        h0 = ex['head'][i0]\n",
    "        h1 = ex['head'][i1]\n",
    "\n",
    "        if self.dep_t == True:\n",
    "            d0 = ex['dep'][i0]\n",
    "            d1 = ex['dep'][i1]\n",
    "        \n",
    "        #either shift, left arc or right arc\n",
    "        #\"Shift\" = 2; \"LA\" = 0; \"RA\" = 1\n",
    "        #if head of the second last word is the last word, then leftarc\n",
    "        if (i1 > 0) and (h1 == i0):\n",
    "            return 0  #action is left arc ---> gold_t\n",
    "        #if head of the last word is the second last word, then rightarc\n",
    "        #make sure nothing in the buffer has head with the last word on the stack\n",
    "        #otherwise, we lose the last word.....\n",
    "        elif (i1 >= 0) and (h0 == i1) and \\\n",
    "                (not any([x for x in buf if ex['head'][x] == i0])):\n",
    "            return 1  #right arc\n",
    "        #otherwise shift, if something is left in buffer, otherwise, do nothing....\n",
    "        else:\n",
    "            return None if len(buf) == 0 else 2  #shift\n",
    "        \n",
    "    def parse(self, dataset, eval_batch_size=5000):\n",
    "        sentences = []\n",
    "        sentence_id_to_idx = {}\n",
    "        \n",
    "        for i, example in enumerate(dataset):\n",
    "            \n",
    "            #example['word']=[188, 186, 186, ..., 59]\n",
    "            #n_words=37\n",
    "            #sentence=[1, 2, 3, 4, 5,.., 37]\n",
    "            \n",
    "            n_words = len(example['word']) - 1\n",
    "            sentence = [j + 1 for j in range(n_words)]            \n",
    "            sentences.append(sentence)\n",
    "            \n",
    "            #mapping the object unique id to the i            \n",
    "            #The id is the object's memory address\n",
    "            sentence_id_to_idx[id(sentence)] = i\n",
    "            \n",
    "        model = ModelWrapper(self, dataset, sentence_id_to_idx)\n",
    "        dependencies = minibatch_parse(sentences, model, eval_batch_size)\n",
    "        \n",
    "        UAS = all_tokens = 0.0\n",
    "        with tqdm(total=len(dataset)) as prog:\n",
    "            for i, ex in enumerate(dataset):\n",
    "                head = [-1] * len(ex['word'])\n",
    "                for h, t, in dependencies[i]:\n",
    "                    head[t] = h\n",
    "                \n",
    "                if (self.pos_t == True) and (self.dep_t == True):\n",
    "                    for pred_h, gold_h, gold_l, pos in \\\n",
    "                            zip(head[1:], ex['head'][1:], ex['dep'][1:], ex['pos'][1:]):\n",
    "                            assert self.id2tok[pos].startswith(P_PREFIX)\n",
    "                            pos_str = self.id2tok[pos][len(P_PREFIX):]\n",
    "                            if (not self.punct(pos_str)):\n",
    "                                UAS += 1 if pred_h == gold_h else 0\n",
    "                                all_tokens += 1\n",
    "\n",
    "                elif (self.pos_t == False) and (self.dep_t == True):\n",
    "                    for pred_h, gold_h, gold_l in \\\n",
    "                            zip(head[1:], ex['head'][1:], ex['dep'][1:]):\n",
    "                            UAS += 1 if pred_h == gold_h else 0\n",
    "                            all_tokens += 1\n",
    "\n",
    "                elif (self.pos_t == True) and (self.dep_t == False):\n",
    "                    for pred_h, gold_h, pos in \\\n",
    "                            zip(head[1:], ex['head'][1:], ex['pos'][1:]):\n",
    "                            assert self.id2tok[pos].startswith(P_PREFIX)\n",
    "                            pos_str = self.id2tok[pos][len(P_PREFIX):]\n",
    "                            if (not self.punct(pos_str)):\n",
    "                                UAS += 1 if pred_h == gold_h else 0\n",
    "                                all_tokens += 1\n",
    "\n",
    "                prog.update(i + 1)\n",
    "        UAS /= all_tokens\n",
    "        return UAS, dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the train_set\n",
    "for ex in train_set:\n",
    "    print(ex)\n",
    "    for w in ex['dep']:\n",
    "        print(w)\n",
    "\n",
    "    print('=' * 1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing training examples that we modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading data\n",
      "2. Building parser\n",
      "took 0.03 seconds\n",
      "Word:  ['ms.', 'haag', 'plays', 'elianti', '.']\n",
      "Pos:  ['NNP', 'NNP', 'VBZ', 'NNP', '.']\n",
      "Head:  [2, 3, 0, 3, 3]\n",
      "Dep:  ['compound', 'nsubj', 'root', 'dobj', 'punct']\n",
      "Word:  [5156, 304, 1364, 1002, 2144, 87]\n",
      "Pos:  [84, 42, 42, 55, 42, 46]\n",
      "Head:  [-1, 2, 3, 0, 3, 3]\n",
      "Dep:  [-1, 23, 2, 0, 10, 11]\n",
      "5. Preprocessing training data...\n",
      "took 1.36 seconds\n",
      "([5155, 5155, 5156, 91, 113, 806, 5155, 5155, 5155, 5155, 5155, 5155, 5155, 5155, 5155, 5155, 5155, 5155, 83, 83, 84, 40, 41, 42, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38], [0, 0, 1], 2)\n"
     ]
    }
   ],
   "source": [
    "# Test our new modify class\n",
    "# 1. Base case, Use all of the features\n",
    "train_set, dev_set, test_set = load_data()\n",
    "print(\"2. Building parser\")\n",
    "start = time.time()\n",
    "parser = Modify_Parser(train_set)\n",
    "print(\"took {:.2f} seconds\".format(time.time() - start))\n",
    "#before numericalize\n",
    "print(\"Word: \", train_set[1][\"word\"])\n",
    "print(\"Pos: \",  train_set[1][\"pos\"])\n",
    "print(\"Head: \", train_set[1][\"head\"])\n",
    "print(\"Dep: \",  train_set[1][\"dep\"])\n",
    "\n",
    "train_set = parser.numericalize(train_set)\n",
    "dev_set   = parser.numericalize(dev_set)\n",
    "test_set  = parser.numericalize(test_set)\n",
    "\n",
    "#after numericalize\n",
    "print(\"Word: \", train_set[1][\"word\"])\n",
    "print(\"Pos: \",  train_set[1][\"pos\"])\n",
    "print(\"Head: \", train_set[1][\"head\"])\n",
    "print(\"Dep: \",  train_set[1][\"dep\"])\n",
    "\n",
    "print(\"5. Preprocessing training data...\",)\n",
    "start = time.time()\n",
    "train_examples = parser.create_instances(train_set)\n",
    "print(\"took {:.2f} seconds\".format(time.time() - start))\n",
    "print(train_examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NULL>\n",
      "<NULL>\n",
      "<ROOT>\n",
      "in\n",
      "an\n",
      "oct.\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<ROOT>\n",
      "<p>:IN\n",
      "<p>:DT\n",
      "<p>:NNP\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "====================================================================================================\n",
      "<d>:root\n",
      "<d>:root\n",
      "<d>:neg\n",
      "====================================================================================================\n",
      "<d>:nsubj\n"
     ]
    }
   ],
   "source": [
    "# Print instance in train_examples to make sure we have word, pos and dep\n",
    "for tok in train_examples[0][0]:\n",
    "    print(parser.id2tok[tok])\n",
    "print(f'=' * 100)\n",
    "for tok in train_examples[0][1]:\n",
    "    print(parser.id2tok[tok])\n",
    "print(f'=' * 100)\n",
    "print(parser.id2tok[train_examples[0][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading data\n",
      "2. Building parser\n",
      "took 0.02 seconds\n",
      "Word:  ['ms.', 'haag', 'plays', 'elianti', '.']\n",
      "Pos:  ['NNP', 'NNP', 'VBZ', 'NNP', '.']\n",
      "Head:  [2, 3, 0, 3, 3]\n",
      "Dep:  ['compound', 'nsubj', 'root', 'dobj', 'punct']\n",
      "Word:  [5110, 258, 1318, 956, 2098, 41]\n",
      "POS NOT FOUND\n",
      "Head:  [-1, 2, 3, 0, 3, 3]\n",
      "Dep:  [-1, 23, 2, 0, 10, 11]\n",
      "5. Preprocessing training data...\n",
      "took 1.63 seconds\n",
      "([5109, 5109, 5110, 45, 67, 760, 5109, 5109, 5109, 5109, 5109, 5109, 5109, 5109, 5109, 5109, 5109, 5109, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38], [0, 0, 1], 2)\n"
     ]
    }
   ],
   "source": [
    "# Case2. Cut POS features\n",
    "train_set, dev_set, test_set = load_data()\n",
    "\n",
    "print(\"2. Building parser\")\n",
    "start = time.time()\n",
    "parser = Modify_Parser(train_set, pos_t=False)\n",
    "print(\"took {:.2f} seconds\".format(time.time() - start))\n",
    "\n",
    "#before numericalize\n",
    "print(\"Word: \", train_set[1][\"word\"])\n",
    "print(\"Pos: \",  train_set[1][\"pos\"])\n",
    "print(\"Head: \", train_set[1][\"head\"])\n",
    "print(\"Dep: \",  train_set[1][\"dep\"])\n",
    "\n",
    "train_set = parser.numericalize(train_set)\n",
    "dev_set   = parser.numericalize(dev_set)\n",
    "test_set  = parser.numericalize(test_set)\n",
    "\n",
    "#after numericalize\n",
    "print(\"Word: \", train_set[1][\"word\"])\n",
    "try:\n",
    "    print(\"Pos: \",  train_set[1][\"pos\"])\n",
    "except:\n",
    "    print('POS NOT FOUND')\n",
    "print(\"Head: \", train_set[1][\"head\"])\n",
    "print(\"Dep: \",  train_set[1][\"dep\"])\n",
    "\n",
    "print(\"5. Preprocessing training data...\",)\n",
    "start = time.time()\n",
    "train_examples = parser.create_instances(train_set)\n",
    "print(\"took {:.2f} seconds\".format(time.time() - start))\n",
    "print(train_examples[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NULL>\n",
      "<NULL>\n",
      "<ROOT>\n",
      "in\n",
      "an\n",
      "oct.\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "<d>:<NULL>\n",
      "====================================================================================================\n",
      "<d>:root\n",
      "<d>:root\n",
      "<d>:neg\n",
      "====================================================================================================\n",
      "<d>:nsubj\n"
     ]
    }
   ],
   "source": [
    "# Print instance in train_examples to make sure we have only word and dep\n",
    "for tok in train_examples[0][0]:\n",
    "    print(parser.id2tok[tok])\n",
    "print(f'=' * 100)\n",
    "for tok in train_examples[0][1]:\n",
    "    print(parser.id2tok[tok])\n",
    "print(f'=' * 100)\n",
    "print(parser.id2tok[train_examples[0][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading data\n",
      "2. Building parser\n",
      "took 0.02 seconds\n",
      "Word:  ['ms.', 'haag', 'plays', 'elianti', '.']\n",
      "Pos:  ['NNP', 'NNP', 'VBZ', 'NNP', '.']\n",
      "Head:  [2, 3, 0, 3, 3]\n",
      "Dep:  ['compound', 'nsubj', 'root', 'dobj', 'punct']\n",
      "Word:  [5117, 265, 1325, 963, 2105, 48]\n",
      "Pos:  [45, 3, 3, 16, 3, 7]\n",
      "Head:  [-1, 2, 3, 0, 3, 3]\n",
      "DEP NOT FOUND\n",
      "5. Preprocessing training data...\n",
      "took 1.69 seconds\n",
      "[[5116, 5116, 5117, 52, 74, 767, 5116, 5116, 5116, 5116, 5116, 5116, 5116, 5116, 5116, 5116, 5116, 5116, 44, 44, 45, 1, 2, 3, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44], 2]\n"
     ]
    }
   ],
   "source": [
    "# Case3. Cut Dep features\n",
    "train_set, dev_set, test_set = load_data()\n",
    "\n",
    "print(\"2. Building parser\")\n",
    "start = time.time()\n",
    "parser = Modify_Parser(train_set, dep_t=False)\n",
    "print(\"took {:.2f} seconds\".format(time.time() - start))\n",
    "\n",
    "#before numericalize\n",
    "print(\"Word: \", train_set[1][\"word\"])\n",
    "print(\"Pos: \",  train_set[1][\"pos\"])\n",
    "print(\"Head: \", train_set[1][\"head\"])\n",
    "print(\"Dep: \",  train_set[1][\"dep\"])\n",
    "\n",
    "train_set = parser.numericalize(train_set)\n",
    "dev_set   = parser.numericalize(dev_set)\n",
    "test_set  = parser.numericalize(test_set)\n",
    "\n",
    "#after numericalize\n",
    "print(\"Word: \", train_set[1][\"word\"])\n",
    "print(\"Pos: \",  train_set[1][\"pos\"])\n",
    "print(\"Head: \", train_set[1][\"head\"])\n",
    "try:\n",
    "    print(\"Dep: \",  train_set[1][\"dep\"])\n",
    "except:\n",
    "    print(\"DEP NOT FOUND\")\n",
    "\n",
    "print(\"5. Preprocessing training data...\",)\n",
    "start = time.time()\n",
    "train_examples = parser.create_instances(train_set)\n",
    "print(\"took {:.2f} seconds\".format(time.time() - start))\n",
    "print(train_examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NULL>\n",
      "<NULL>\n",
      "<ROOT>\n",
      "in\n",
      "an\n",
      "oct.\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<ROOT>\n",
      "<p>:IN\n",
      "<p>:DT\n",
      "<p>:NNP\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "<p>:<NULL>\n",
      "====================================================================================================\n",
      "<p>:DT\n"
     ]
    }
   ],
   "source": [
    "# Print instance in train_examples to make sure we have only word and pos\n",
    "for tok in train_examples[0][0]:\n",
    "    print(parser.id2tok[tok])\n",
    "print(f'=' * 100)\n",
    "print(parser.id2tok[train_examples[0][1]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify training function\n",
    "\n",
    "The training function is almost identical to the one provided by Chaky. I just insert some print to debugging and tracking the input shape and modify minibatchs to make it's work without dependencies features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modify_train(parser, train_data, dev_data, output_path, batch_size=1024, n_epochs=10, lr=0.0005, dep_t=True):\n",
    "    \n",
    "    best_dev_UAS = 0\n",
    "    \n",
    "    optimizer = optim.Adam(parser.model.parameters(), lr=0.001)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {:} out of {:}\".format(epoch + 1, n_epochs))\n",
    "        dev_UAS = Modify_train_for_epoch(\n",
    "            parser, train_data, dev_data, optimizer, loss_func, batch_size, dep_t)\n",
    "        print(f'Current UAS scores = {dev_UAS}')\n",
    "        if dev_UAS > best_dev_UAS:\n",
    "            best_dev_UAS = dev_UAS\n",
    "            print(\"New best dev UAS! Saving model.\")\n",
    "            torch.save(parser.model.state_dict(), output_path)\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "def Modify_train_for_epoch(parser, train_data, dev_data, optimizer, loss_func, batch_size, dep_t=True):\n",
    "    \n",
    "    parser.model.train()  # Places model in \"train\" mode, i.e. apply dropout layer\n",
    "    n_minibatches = math.ceil(len(train_data) / batch_size)\n",
    "    loss_meter = AverageMeter()\n",
    "\n",
    "    with tqdm(total=(n_minibatches)) as prog:\n",
    "        if dep_t == True:\n",
    "            for i, (train_x, train_y) in enumerate(minibatches(train_data, batch_size)):\n",
    "                \n",
    "                #train_x:  batch_size, n_features\n",
    "                #train_y:  batch_size, target(=3)\n",
    "                \n",
    "                optimizer.zero_grad() \n",
    "                loss = 0.\n",
    "                train_x = torch.from_numpy(train_x).long()  #long() for int so embedding works....\n",
    "                train_y = torch.from_numpy(train_y.nonzero()[1]).long()  #get the index with 1 because torch expects label to be single integer\n",
    "\n",
    "                # Forward pass: compute predicted logits.\n",
    "                logits = parser.model(train_x)\n",
    "                # Compute loss\n",
    "                #print(logits.shape, train_y.shape)\n",
    "                loss = loss_func(logits, train_y)\n",
    "                # Compute gradients of the loss w.r.t model parameters.\n",
    "                loss.backward()\n",
    "                # Take step with optimizer.\n",
    "                optimizer.step()\n",
    "\n",
    "                prog.update(1)\n",
    "                loss_meter.update(loss.item())\n",
    "        else:\n",
    "            for i, (train_x, train_y) in enumerate(Modify_minibatches(train_data, batch_size, dep_t=False)):\n",
    "            \n",
    "                #train_x:  batch_size, n_features\n",
    "                #train_y:  batch_size, target(=3)\n",
    "                \n",
    "                optimizer.zero_grad() \n",
    "                loss = 0.\n",
    "                train_x = torch.from_numpy(train_x).long()  #long() for int so embedding works....\n",
    "                train_y = torch.from_numpy(train_y.nonzero()[1]).long()  #get the index with 1 because torch expects label to be single integer\n",
    "\n",
    "                # Forward pass: compute predicted logits.\n",
    "                logits = parser.model(train_x)\n",
    "                # Compute loss\n",
    "                #print(logits.shape, train_y.shape)\n",
    "                loss = loss_func(logits, train_y)\n",
    "                # Compute gradients of the loss w.r.t model parameters.\n",
    "                loss.backward()\n",
    "                # Take step with optimizer.\n",
    "                optimizer.step()\n",
    "\n",
    "                prog.update(1)\n",
    "                loss_meter.update(loss.item())\n",
    "\n",
    "    print(\"Average Train Loss: {}\".format(loss_meter.avg))\n",
    "    print(\"Evaluating on dev set\",)\n",
    "    parser.model.eval()  # Places model in \"eval\" mode, i.e. don't apply dropout layer\n",
    "        \n",
    "    dev_UAS, _ = parser.parse(dev_data)\n",
    "    print(\"- dev UAS: {:.2f}\".format(dev_UAS * 100.0))\n",
    "    return dev_UAS\n",
    "\n",
    "def Modify_minibatches(data, batch_size, dep_t=True):\n",
    "\n",
    "    if dep_t == True:\n",
    "        x = np.array([d[0] for d in data])\n",
    "        y = np.array([d[2] for d in data])\n",
    "        #print(x.shape)\n",
    "        #print(y.shape)\n",
    "        one_hot = np.zeros((y.size, 3))\n",
    "        #print(one_hot.shape)\n",
    "        one_hot[np.arange(y.size), y] = 1\n",
    "    \n",
    "    if dep_t == False:\n",
    "        x = np.array([d[0] for d in data])\n",
    "        y = np.array([d[1] for d in data])\n",
    "        #print(x.shape)\n",
    "        #print(y.shape)\n",
    "        one_hot = np.zeros((y.size, 3))\n",
    "        #print(one_hot.shape)\n",
    "        one_hot[np.arange(y.size), y] = 1\n",
    "\n",
    "    return get_minibatches([x, one_hot], batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing with words + dep features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading data\n",
      "2. Building parser\n",
      "took 0.02 seconds\n",
      "4. Loading pretrained embeddings...\n",
      "Embedding matrix shape (vocab, emb size):  (5111, 50)\n",
      "took 3.10 seconds\n",
      "5. Preprocessing training data...\n",
      "took 1.33 seconds\n"
     ]
    }
   ],
   "source": [
    "# pos_t\n",
    "train_set, dev_set, test_set = load_data()\n",
    "\n",
    "print(\"2. Building parser\")\n",
    "start = time.time()\n",
    "parser = Modify_Parser(train_set, pos_t=False)\n",
    "print(\"took {:.2f} seconds\".format(time.time() - start))\n",
    "\n",
    "train_set = parser.numericalize(train_set)\n",
    "dev_set   = parser.numericalize(dev_set)\n",
    "test_set  = parser.numericalize(test_set)\n",
    "\n",
    "print(\"4. Loading pretrained embeddings...\",)\n",
    "start = time.time()\n",
    "word_vectors = {}\n",
    "for line in open(\"/root/projects/NLP/Assignment/26_Jan_Depedency_Parser/en-cw.txt\").readlines():\n",
    "    we = line.strip().split() #we = word embeddings - first column: word;  the rest is embedding\n",
    "    word_vectors[we[0]] = [float(x) for x in we[1:]] #{word: [list of 50 numbers], nextword: [another list], so on...}\n",
    "    \n",
    "#create an empty embedding matrix holding the embedding lookup table (vocab size, embed dim)\n",
    "#we use random.normal instead of zeros, to keep the embedding matrix arbitrary in case word vectors don't exist....\n",
    "embeddings_matrix = np.asarray(np.random.normal(0, 0.9, (parser.n_tokens, 50)), dtype='float32')\n",
    "\n",
    "for token in parser.tok2id:\n",
    "        i = parser.tok2id[token]\n",
    "        if token in word_vectors:\n",
    "            embeddings_matrix[i] = word_vectors[token]\n",
    "        elif token.lower() in word_vectors:\n",
    "            embeddings_matrix[i] = word_vectors[token.lower()]\n",
    "print(\"Embedding matrix shape (vocab, emb size): \", embeddings_matrix.shape)\n",
    "print(\"took {:.2f} seconds\".format(time.time() - start))\n",
    "\n",
    "print(\"5. Preprocessing training data...\",)\n",
    "start = time.time()\n",
    "train_examples = parser.create_instances(train_set)\n",
    "print(\"took {:.2f} seconds\".format(time.time() - start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING\n",
      "================================================================================\n",
      "Epoch 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 28.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.5974723690499862\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 20367408.83it/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 47.76\n",
      "Current UAS scores = 0.477630592351912\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 26.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.34098678020139533\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 20733969.14it/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 53.07\n",
      "Current UAS scores = 0.5307006581687911\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 3 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 27.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.2744910266871254\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 21006740.88it/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 55.04\n",
      "Current UAS scores = 0.5503624093976506\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 4 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 25.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.2373795717333754\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 18100074.97it/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 58.64\n",
      "Current UAS scores = 0.5863534116470882\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 5 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 30.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.20463531961043677\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 19079558.95it/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 61.63\n",
      "Current UAS scores = 0.6162626010164126\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 6 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 29.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.18137155938893557\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 17367072.50it/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 62.63\n",
      "Current UAS scores = 0.6262601016412563\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 7 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 29.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.1628534517561396\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 15496654.16it/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 62.86\n",
      "Current UAS scores = 0.6285928517870533\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 8 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 25.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.14863442443311214\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 19082331.13it/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 64.89\n",
      "Current UAS scores = 0.6489211030575689\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 9 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 26.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.1326194697370132\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 20855793.24it/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 64.90\n",
      "Current UAS scores = 0.649004415562776\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 10 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 29.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.12211900468294819\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 19068478.26it/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 66.22\n",
      "Current UAS scores = 0.662167791385487\n",
      "New best dev UAS! Saving model.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#create directory if it does not exist for saving the weights...\n",
    "output_dir = \"output/{:%Y%m%d_%H%M%S}_pos_t_False/\".format(datetime.now())\n",
    "output_path = output_dir + \"model.weights_test\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "print(80 * \"=\")\n",
    "print(\"TRAINING\")\n",
    "print(80 * \"=\")\n",
    "    \n",
    "model = ParserModel(embeddings_matrix, n_features=30) # Because now we only use 2 features (18 + 12)\n",
    "parser.model = model\n",
    "\n",
    "start = time.time()\n",
    "Modify_train(parser, train_examples, dev_set, output_path,\n",
    "      batch_size=1024, n_epochs=10, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TESTING pos_t False\n",
      "================================================================================\n",
      "Restoring the best model weights found on the dev set\n",
      "Final evaluation on test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 14542188.96it/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- test UAS: 67.38\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(80 * \"=\")\n",
    "print(\"TESTING pos_t False\")\n",
    "print(80 * \"=\")\n",
    "\n",
    "print(\"Restoring the best model weights found on the dev set\")\n",
    "parser.model.load_state_dict(torch.load(output_path))\n",
    "print(\"Final evaluation on test set\",)\n",
    "parser.model.eval()\n",
    "UAS, dependencies = parser.parse(test_set)\n",
    "print(\"- test UAS: {:.2f}\".format(UAS * 100.0))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing with words + pos features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading data\n",
      "2. Building parser\n",
      "took 0.03 seconds\n",
      "4. Loading pretrained embeddings...\n",
      "Embedding matrix shape (vocab, emb size):  (5118, 50)\n",
      "took 3.44 seconds\n",
      "5. Preprocessing training data...\n",
      "took 1.60 seconds\n"
     ]
    }
   ],
   "source": [
    "# dep_t\n",
    "train_set, dev_set, test_set = load_data()\n",
    "\n",
    "print(\"2. Building parser\")\n",
    "start = time.time()\n",
    "parser = Modify_Parser(train_set, dep_t=False)\n",
    "print(\"took {:.2f} seconds\".format(time.time() - start))\n",
    "\n",
    "train_set = parser.numericalize(train_set)\n",
    "dev_set   = parser.numericalize(dev_set)\n",
    "test_set  = parser.numericalize(test_set)\n",
    "\n",
    "print(\"4. Loading pretrained embeddings...\",)\n",
    "start = time.time()\n",
    "word_vectors = {}\n",
    "for line in open(\"/root/projects/NLP/Assignment/26_Jan_Depedency_Parser/en-cw.txt\").readlines():\n",
    "    we = line.strip().split() #we = word embeddings - first column: word;  the rest is embedding\n",
    "    word_vectors[we[0]] = [float(x) for x in we[1:]] #{word: [list of 50 numbers], nextword: [another list], so on...}\n",
    "    \n",
    "#create an empty embedding matrix holding the embedding lookup table (vocab size, embed dim)\n",
    "#we use random.normal instead of zeros, to keep the embedding matrix arbitrary in case word vectors don't exist....\n",
    "embeddings_matrix = np.asarray(np.random.normal(0, 0.9, (parser.n_tokens, 50)), dtype='float32')\n",
    "\n",
    "for token in parser.tok2id:\n",
    "        i = parser.tok2id[token]\n",
    "        if token in word_vectors:\n",
    "            embeddings_matrix[i] = word_vectors[token]\n",
    "        elif token.lower() in word_vectors:\n",
    "            embeddings_matrix[i] = word_vectors[token.lower()]\n",
    "print(\"Embedding matrix shape (vocab, emb size): \", embeddings_matrix.shape)\n",
    "print(\"took {:.2f} seconds\".format(time.time() - start))\n",
    "\n",
    "print(\"5. Preprocessing training data...\",)\n",
    "start = time.time()\n",
    "train_examples = parser.create_instances(train_set)\n",
    "print(\"took {:.2f} seconds\".format(time.time() - start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING\n",
      "================================================================================\n",
      "Epoch 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:02<00:00, 21.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.5280717276036739\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 7095978.50it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 60.80\n",
      "Current UAS scores = 0.6080363912054587\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:02<00:00, 21.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.2826758998756607\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 6602940.84it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 66.07\n",
      "Current UAS scores = 0.6607278241091736\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 3 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:02<00:00, 21.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.22822186816483736\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 6133025.63it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 68.28\n",
      "Current UAS scores = 0.6828089461713419\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 4 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:02<00:00, 23.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.19149618006000915\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 6915326.08it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 71.66\n",
      "Current UAS scores = 0.7166413949962093\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 5 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 26.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.1650849375873804\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 7394107.87it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 71.78\n",
      "Current UAS scores = 0.7177786201667931\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 6 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 26.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.14467006161188087\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 6981959.22it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 73.41\n",
      "Current UAS scores = 0.7340788476118272\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 7 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 24.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.12896656058728695\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 7158051.75it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 74.91\n",
      "Current UAS scores = 0.7490523123578469\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 8 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:02<00:00, 23.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.11613588795686762\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 6641003.43it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 74.60\n",
      "Current UAS scores = 0.7460197119029568\n",
      "\n",
      "Epoch 9 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:02<00:00, 23.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.10431490031381448\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 6797657.62it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 75.14\n",
      "Current UAS scores = 0.7514215314632298\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 10 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:02<00:00, 22.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.09518044007321198\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 6929921.72it/s]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 75.62\n",
      "Current UAS scores = 0.7561599696739955\n",
      "New best dev UAS! Saving model.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#create directory if it does not exist for saving the weights...\n",
    "output_dir = \"output/{:%Y%m%d_%H%M%S}_dep_t_False/\".format(datetime.now())\n",
    "output_path = output_dir + \"model.weights_dep_t\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "print(80 * \"=\")\n",
    "print(\"TRAINING\")\n",
    "print(80 * \"=\")\n",
    "    \n",
    "model = ParserModel(embeddings_matrix, n_features=36) # Because now we only use 2 features (18 + 18)\n",
    "parser.model = model\n",
    "\n",
    "start = time.time()\n",
    "Modify_train(parser, train_examples, dev_set, output_path,\n",
    "      batch_size=1024, n_epochs=10, lr=0.0005, dep_t=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TESTING dep_t False\n",
      "================================================================================\n",
      "Restoring the best model weights found on the dev set\n",
      "Final evaluation on test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125250it [00:00, 5275681.89it/s]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- test UAS: 77.68\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(80 * \"=\")\n",
    "print(\"TESTING dep_t False\")\n",
    "print(80 * \"=\")\n",
    "\n",
    "print(\"Restoring the best model weights found on the dev set\")\n",
    "parser.model.load_state_dict(torch.load(output_path))\n",
    "print(\"Final evaluation on test set\",)\n",
    "parser.model.eval()\n",
    "UAS, dependencies = parser.parse(test_set)\n",
    "print(\"- test UAS: {:.2f}\".format(UAS * 100.0))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Comparision\n",
    "\n",
    "Now, we got the results with the pre-embedding (I mean, the embedding that we borrow from somewhere on the internet.) Let's try to train our embedding by ourself and then try to compare with the results that we got above."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "We will use the same data from above, Chaky already provide us the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading data\n"
     ]
    }
   ],
   "source": [
    "train_set, dev_set, test_set = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ms.', 'haag', 'plays', 'elianti', '.']\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Actually, we can also use Chaky Parser from above to directly numericalize but it is a bit convenience\n",
    "# So, we will do it by ourself.\n",
    "\n",
    "# Extract only word out from the train_set. If you notice this is the corpus!\n",
    "corpus = [word['word'] for word in train_set]\n",
    "\n",
    "# Check results\n",
    "print(corpus[1])\n",
    "print(len(corpus)) # It's 1,000 because we cut it in the dataloader function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['slowed', 'organizations', 'fact', 'games', 'pulling']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let create vocab for the word\n",
    "# Flatten and get Unique words\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "vocab = list(set(flatten(corpus)))\n",
    "vocab[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601\n",
      "car\n"
     ]
    }
   ],
   "source": [
    "# Word2index and Index2word\n",
    "\n",
    "# assign id to those vocabs\n",
    "word2index = dict()\n",
    "word2index.update({\"<UNK>\":  0})\n",
    "for idx, v in enumerate(vocab):\n",
    "        word2index.update({v:  idx + 1})\n",
    "\n",
    "#add <UNK>, which is a very normal token exists in the world\n",
    "vocab.append('<UNK>') #chaky, can it be ##UNK, or UNKKKKKK, or anything\n",
    "\n",
    "# Testing\n",
    "print(word2index['car'])\n",
    "\n",
    "# index2word\n",
    "index2word = {v:k for k, v in word2index.items()}\n",
    "\n",
    "print(index2word[word2index['car']])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data/Function prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "# Build co-occurance matrix\n",
    "from collections import Counter\n",
    "X_i = Counter(flatten(corpus)) # X_i\n",
    "print(X_i['car'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to create skipgram, basically fix a bit from\n",
    "# generated batch function\n",
    "def skip_grams_generated(window_size=1):\n",
    "\n",
    "# I fix a little from Chaky so we can modify the window_size\n",
    "    \n",
    "    # Make skip gram of one size window\n",
    "    skip_grams = []\n",
    "    # loop each word sequence\n",
    "    # we starts from 1 because 0 has no context\n",
    "    # we stop at second last for the same reason\n",
    "    for sent in corpus:\n",
    "        for i in range(1, len(sent) - 1): # So we can modify the window size\n",
    "            target = sent[i]\n",
    "            \n",
    "            context = list()\n",
    "            # ['a', 'b', 'c', 'd', 'e'] if window size = 2 and target is c\n",
    "            # this is basically append 'b', 'd', 'a', 'e' into context\n",
    "            \n",
    "            for j in range(window_size):\n",
    "                \n",
    "                if i - (j + 1) >= 0: # Check if it outside of range from the left of list\n",
    "                    context.append(sent[i - (j + 1)])\n",
    "                    #context.append(word2index[sent[i - (j + 1)]])\n",
    "                \n",
    "                if i + (j + 1) < len(sent): # Check if it outside of range from the right of list\n",
    "                    context.append(sent[i + (j + 1)])\n",
    "\n",
    "            for w in context:\n",
    "                skip_grams.append((target, w)) # Return tuple instead of list because we want to use count\n",
    "                                                # function later\n",
    "    \n",
    "    return skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find co-occurance in skip_grams with window of 2\n",
    "X_ik_skipgram = Counter(skip_grams_generated(window_size=2))\n",
    "\n",
    "X_ik_skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight function\n",
    "\n",
    "#simply a normalized function...don't worry too much\n",
    "def weighting(w_i, w_j, X_ik):\n",
    "        \n",
    "    #check whether the co-occurrences exist between these two words\n",
    "    try:\n",
    "        x_ij = X_ik[(w_i, w_j)]\n",
    "    except:\n",
    "        x_ij = 1  #if does not exist, set it to 1, basically smoothing technique\n",
    "                \n",
    "    x_max = 100 #100 # fixed in paper  #cannot exceed 100 counts\n",
    "    alpha = 0.75 # Followed Chaky way!\n",
    "    \n",
    "    #if co-occurrence does not exceed 100, scale it based on some alpha\n",
    "    if x_ij < x_max:\n",
    "        result = (x_ij/x_max)**alpha  #scale it\n",
    "    else:\n",
    "        result = 1  #if is greater than max, set it to 1 maximum\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 12854985/25704900 [00:53<00:53, 241068.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "from tqdm import tqdm\n",
    "\n",
    "X_ik = {}  #for keeping the co-occurences\n",
    "weighting_dic = {} #scaling the percentage of sampling\n",
    "# Use tqdm as amanda recommend!\n",
    "with tqdm(total=len(vocab) ** 2) as prog:\n",
    "    for bigram in combinations_with_replacement(vocab, 2):\n",
    "        if X_ik_skipgram.get(bigram) is not None:  #matches \n",
    "            co_occer = X_ik_skipgram[bigram]  #get the count from what we already counted\n",
    "            X_ik[bigram] = co_occer + 1 # + 1 for stability issue\n",
    "            X_ik[(bigram[1],bigram[0])] = co_occer+1   #count also for the opposite\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "        prog.update(1)\n",
    "        weighting_dic[bigram] = weighting(bigram[0], bigram[1], X_ik)\n",
    "        weighting_dic[(bigram[1], bigram[0])] = weighting(bigram[1], bigram[0], X_ik)\n",
    "\n",
    "    # Do not print if you have large data, otherwise your pc will froze.\n",
    "    #print(f\"{X_ik=}\")\n",
    "    #print(f\"{weighting_dic=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def random_batch(batch_size, word_sequence, skip_grams, X_ik, weighting_dic):\n",
    "    \n",
    "    #convert to id since our skip_grams is word, not yet id\n",
    "    skip_grams_id = [(word2index[skip_gram[0]], word2index[skip_gram[1]]) for skip_gram in skip_grams]\n",
    "    \n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    random_coocs  = []\n",
    "    random_weightings = []\n",
    "    random_index = np.random.choice(range(len(skip_grams_id)), batch_size, replace=False) #randomly pick without replacement\n",
    "        \n",
    "    for i in random_index:\n",
    "        random_inputs.append([skip_grams_id[i][0]])  # target, e.g., 2\n",
    "        random_labels.append([skip_grams_id[i][1]])  # context word, e.g., 3\n",
    "        \n",
    "        #get cooc\n",
    "        pair = skip_grams[i]\n",
    "        try:\n",
    "            cooc = X_ik[pair]\n",
    "        except:\n",
    "            cooc = 1\n",
    "        random_coocs.append([math.log(cooc)])\n",
    "        \n",
    "        #get weighting\n",
    "        weighting = weighting_dic[pair]\n",
    "        random_weightings.append([weighting])\n",
    "                    \n",
    "    return np.array(random_inputs), np.array(random_labels), np.array(random_coocs), np.array(random_weightings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [[3065]\n",
      " [ 602]]\n",
      "Target:  [[ 370]\n",
      " [4548]]\n",
      "Cooc:  [[1.38629436]\n",
      " [0.69314718]]\n",
      "Weighting:  [[0.08944272]\n",
      " [0.05318296]]\n"
     ]
    }
   ],
   "source": [
    "#testing the method\n",
    "batch_size = 2 # mini-batch size\n",
    "skip_grams = skip_grams_generated(window_size=2)\n",
    "input_batch, target_batch, cooc_batch, weighting_batch = random_batch(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
    "\n",
    "print(\"Input: \", input_batch)\n",
    "print(\"Target: \", target_batch)\n",
    "print(\"Cooc: \", cooc_batch)\n",
    "print(\"Weighting: \", weighting_batch)\n",
    "\n",
    "#we will convert them to tensor during training, so don't worry..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloVe(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size,embed_size):\n",
    "        super(GloVe,self).__init__()\n",
    "        self.embedding_v = nn.Embedding(vocab_size, embed_size) # center embedding\n",
    "        self.embedding_u = nn.Embedding(vocab_size, embed_size) # out embedding\n",
    "        \n",
    "        self.v_bias = nn.Embedding(vocab_size, 1)\n",
    "        self.u_bias = nn.Embedding(vocab_size, 1)\n",
    "        \n",
    "    def forward(self, center_words, target_words, coocs, weighting):\n",
    "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
    "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
    "        \n",
    "        center_bias = self.v_bias(center_words).squeeze(1)\n",
    "        target_bias = self.u_bias(target_words).squeeze(1)\n",
    "        \n",
    "        inner_product = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
    "        \n",
    "        #note that coocs already got log\n",
    "        loss = weighting*torch.pow(inner_product +center_bias + target_bias - coocs, 2)\n",
    "        \n",
    "        return torch.sum(loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# We are nvidia fanboys, so CUDA!!!\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare parameters\n",
    "voc_size = len(vocab)\n",
    "batch_size     = 10 # mini-batch size\n",
    "embedding_size = 50\n",
    "model          = GloVe(voc_size, embedding_size)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_training = time.time()\n",
    "# Training\n",
    "num_epochs = 5000\n",
    "with tqdm(total=num_epochs) as prog:\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        input_batch, target_batch, cooc_batch, weighting_batch = random_batch(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
    "        input_batch  = torch.LongTensor(input_batch).to(device)         #[batch_size, 1]\n",
    "        target_batch = torch.LongTensor(target_batch).to(device)        #[batch_size, 1]\n",
    "        cooc_batch   = torch.FloatTensor(cooc_batch).to(device)         #[batch_size, 1]\n",
    "        weighting_batch = torch.FloatTensor(weighting_batch).to(device) #[batch_size, 1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = model(input_batch, target_batch, cooc_batch, weighting_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        epoch_mins, epoch_secs = epoch_time(start, end)\n",
    "        \n",
    "\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n",
    "        \n",
    "        prog.update(1)\n",
    "\n",
    "end_training = time.time()\n",
    "start_min, end_min = epoch_time(start_training, end_training)\n",
    "print(f'Total time: {start_min}m {end_min}s\")')\n",
    "\n",
    "# Save model\n",
    "path = '/root/projects/NLP/Assignment/26_Jan_Depedency_Parser/output/Glove_weight/Glove_5000.pth'\n",
    "torch.save(model.state_dict(), path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some functions\n",
    "#numpy version\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "    return cos_sim\n",
    "\n",
    "# Function to get embedding\n",
    "def get_embed(word, current_model):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except :\n",
    "        index = word2index['<UNK>'] #unknown\n",
    "    word = torch.LongTensor([index]).to(device)\n",
    "    \n",
    "    embed =  (current_model.embedding_v(word)+current_model.embedding_u(word))/2\n",
    "    return np.array(embed[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Let's declare some list of word that we want to plot\n",
    "cos_test_word_list = ['employer', 'worker', 'company', 'organization', 'manufacturing', '26',\n",
    "'people', 'mountain', 'resigning', 'man']\n",
    "\n",
    "# Convert them to embed\n",
    "cos_test_emb_list = [get_embed(word, model) for word in cos_test_word_list]\n",
    "print(len(cos_test_emb_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.500715</td>\n",
       "      <td>1.984619</td>\n",
       "      <td>employer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.061187</td>\n",
       "      <td>-1.509704</td>\n",
       "      <td>worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.307892</td>\n",
       "      <td>2.227030</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.078542</td>\n",
       "      <td>-1.752178</td>\n",
       "      <td>organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.241868</td>\n",
       "      <td>3.347566</td>\n",
       "      <td>manufacturing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y           word\n",
       "0  3.500715  1.984619       employer\n",
       "1 -1.061187 -1.509704         worker\n",
       "2  1.307892  2.227030        company\n",
       "3  1.078542 -1.752178   organization\n",
       "4 -2.241868  3.347566  manufacturing"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "pca = PCA(n_components=2)\n",
    "reduced = pca.fit(cos_test_emb_list).transform(cos_test_emb_list)\n",
    "reduced = pd.DataFrame(reduced,columns=['X','Y'])\n",
    "reduced['word'] = cos_test_word_list #adding columns\n",
    "reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(x=reduced['X'],y=reduced['Y'])\n",
    "plt.title('Glove Cosine similarity')\n",
    "for idx, value in reduced.iterrows():\n",
    "    plt.annotate(reduced['word'][idx],value[:-1])\n",
    "\n",
    "path = '/root/projects/NLP/Assignment/26_Jan_Depedency_Parser/output/Glove_weight/Glove_fig.png'\n",
    "plt.savefig(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data/Function prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the same dataset and code from data preparation\n",
    "def random_batch(batch_size, word_sequence, window_size=1):\n",
    "\n",
    "# I fix a little from Chaky so we can modify the window_size\n",
    "    \n",
    "    # Make skip gram of one size window\n",
    "    skip_grams = []\n",
    "    # loop each word sequence\n",
    "    # we starts from 1 because 0 has no context\n",
    "    # we stop at second last for the same reason\n",
    "    for sent in corpus:\n",
    "        for i in range(1, len(sent) - 1): # So we can modify the window size\n",
    "            target = word2index[sent[i]]\n",
    "            \n",
    "            context = list()\n",
    "            # ['a', 'b', 'c', 'd', 'e'] if window size = 2 and target is c\n",
    "            # this is basically append 'b', 'd', 'a', 'e' into context\n",
    "            \n",
    "            for j in range(window_size):\n",
    "                \n",
    "                if i - (j + 1) >= 0: # Check if it outside of range from the left of list\n",
    "                    context.append(word2index[sent[i - (j + 1)]])\n",
    "                \n",
    "                if i + (j + 1) < len(sent): # Check if it outside of range from the right of list\n",
    "                    context.append(word2index[sent[i + (j + 1)]])\n",
    "            \n",
    "            #context = [word2index[sent[i - 1]], word2index[sent[i + 1]]]\n",
    "            for w in context:\n",
    "                skip_grams.append([target, w])\n",
    "    \n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False) #randomly pick without replacement\n",
    "        \n",
    "    for i in random_index:\n",
    "        random_inputs.append([skip_grams[i][0]])  # target, e.g., 2\n",
    "        random_labels.append([skip_grams[i][1]])  # context word, e.g., 3\n",
    "            \n",
    "    return np.array(random_inputs), np.array(random_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [[2105]\n",
      " [1108]\n",
      " [2832]\n",
      " [4808]\n",
      " [1992]\n",
      " [2082]\n",
      " [3547]\n",
      " [2350]\n",
      " [2709]\n",
      " [4548]]\n",
      "Target:  [[4976]\n",
      " [4073]\n",
      " [ 713]\n",
      " [2083]\n",
      " [2903]\n",
      " [ 906]\n",
      " [3801]\n",
      " [3065]\n",
      " [4745]\n",
      " [ 967]]\n"
     ]
    }
   ],
   "source": [
    "#testing the method\n",
    "batch_size = 10 # mini-batch size\n",
    "input_batch, target_batch = random_batch(batch_size, corpus, 2)\n",
    "\n",
    "print(\"Input: \", input_batch)\n",
    "print(\"Target: \", target_batch)\n",
    "#we will convert them to tensor during training, so don't worry..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        super(Skipgram,self).__init__()\n",
    "        self.embedding_v = nn.Embedding(vocab_size, emb_size)\n",
    "        self.embedding_u = nn.Embedding(vocab_size, emb_size)\n",
    "    \n",
    "    def forward(self, center_words, target_words, all_vocabs):\n",
    "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
    "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
    "        all_embeds    = self.embedding_u(all_vocabs) #   [batch_size, voc_size, emb_size]\n",
    "        \n",
    "        scores      = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
    "\n",
    "        norm_scores = all_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        #[batch_size, voc_size, emb_size] @ [batch_size, emb_size, 1] = [batch_size, voc_size, 1] = [batch_size, voc_size]\n",
    "\n",
    "        nll = -torch.mean(torch.log(torch.exp(scores)/torch.sum(torch.exp(norm_scores), 1).unsqueeze(1))) # log-softmax\n",
    "        # scalar (loss must be scalar)    \n",
    "            \n",
    "        return nll # negative log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5070])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_sequence(seq, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)\n",
    "\n",
    "#use for the normalized term in the probability calculation\n",
    "all_vocabs = prepare_sequence(list(vocab), word2index).expand(batch_size, len(vocab))  # [batch_size, voc_size]\n",
    "all_vocabs.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skipgram training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size     = 10 # mini-batch size\n",
    "embedding_size = 50 #so we can later plot\n",
    "model          = Skipgram(voc_size, embedding_size)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1000/5000 [02:56<11:42,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000 | cost: 18.447308 | time: 2m 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 1999/5000 [05:53<09:55,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 | cost: 18.276245 | time: 2m 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3000/5000 [08:50<06:36,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3000 | cost: 17.172071 | time: 2m 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4000/5000 [11:54<03:04,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4000 | cost: 14.540049 | time: 3m 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [14:52<00:00,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 | cost: 17.496342 | time: 2m 57s\n",
      "Total time use in skipgram with window size of 1 14 miniute(s) 52 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Training\n",
    "start_train_time = time.time()\n",
    "num_epochs = 5000\n",
    "start = time.time()\n",
    "with tqdm(total=num_epochs) as prog:\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        input_batch, target_batch = random_batch(batch_size, corpus, window_size=2)\n",
    "        input_batch  = torch.LongTensor(input_batch)  #[batch_size, 1]\n",
    "        target_batch = torch.LongTensor(target_batch) #[batch_size, 1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(input_batch, target_batch, all_vocabs)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 1000 == 0:\n",
    "            end = time.time()\n",
    "            epoch_mins, epoch_secs = epoch_time(start, end)\n",
    "            print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n",
    "            start = time.time()\n",
    "        prog.update(1)\n",
    "\n",
    "end_train_time = time.time()\n",
    "train_time_mins, train_time_secs = epoch_time(start_train_time, end_train_time)\n",
    "print(f'Total time use in skipgram with window size of 1 {train_time_mins} miniute(s) {train_time_secs} second')\n",
    "\n",
    "path = '/root/projects/NLP/Assignment/26_Jan_Depedency_Parser/output/Skipgram_weight/Skipgram_5000.pth'\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Let's declare some list of word that we want to plot\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "cos_test_word_list = ['employer', 'worker', 'company', 'organization', 'manufacturing', '26',\n",
    "'people', 'mountain', 'resigning', 'man']\n",
    "\n",
    "# Convert them to embed\n",
    "cos_test_emb_list = [get_embed(word, model) for word in cos_test_word_list]\n",
    "print(len(cos_test_emb_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.944754</td>\n",
       "      <td>-1.520992</td>\n",
       "      <td>employer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.745860</td>\n",
       "      <td>-0.101556</td>\n",
       "      <td>worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.408631</td>\n",
       "      <td>1.010221</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.068842</td>\n",
       "      <td>1.093792</td>\n",
       "      <td>organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.998793</td>\n",
       "      <td>-2.682834</td>\n",
       "      <td>manufacturing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y           word\n",
       "0  0.944754 -1.520992       employer\n",
       "1 -0.745860 -0.101556         worker\n",
       "2 -0.408631  1.010221        company\n",
       "3 -2.068842  1.093792   organization\n",
       "4  0.998793 -2.682834  manufacturing"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "pca = PCA(n_components=2)\n",
    "reduced = pca.fit(cos_test_emb_list).transform(cos_test_emb_list)\n",
    "reduced = pd.DataFrame(reduced,columns=['X','Y'])\n",
    "reduced['word'] = cos_test_word_list #adding columns\n",
    "reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(x=reduced['X'],y=reduced['Y'])\n",
    "plt.title('Skipgrams Cosine similarity')\n",
    "for idx, value in reduced.iterrows():\n",
    "    plt.annotate(reduced['word'][idx],value[:-1])\n",
    "\n",
    "path = '/root/projects/NLP/Assignment/26_Jan_Depedency_Parser/output/Skipgram_weight/Skipgrams_fig.png'\n",
    "plt.savefig(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-embeded dataset\n",
    "We do not need to do anything new, we just need to use the same code from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading data\n",
      "2. Building parser\n",
      "took 0.05 seconds\n",
      "4. Loading pretrained embeddings...\n",
      "Embedding matrix shape (vocab, emb size):  (5157, 50)\n",
      "took 6.97 seconds\n"
     ]
    }
   ],
   "source": [
    "train_set, dev_set, test_set = load_data()\n",
    "\n",
    "print(\"2. Building parser\")\n",
    "start = time.time()\n",
    "parser = Parser(train_set)\n",
    "print(\"took {:.2f} seconds\".format(time.time() - start))\n",
    "\n",
    "train_set = parser.numericalize(train_set)\n",
    "dev_set   = parser.numericalize(dev_set)\n",
    "test_set  = parser.numericalize(test_set)\n",
    "\n",
    "print(\"4. Loading pretrained embeddings...\",)\n",
    "start = time.time()\n",
    "word_vectors = {}\n",
    "for line in open(\"/root/projects/NLP/Assignment/26_Jan_Depedency_Parser/en-cw.txt\").readlines():\n",
    "    we = line.strip().split() #we = word embeddings - first column: word;  the rest is embedding\n",
    "    word_vectors[we[0]] = [float(x) for x in we[1:]] #{word: [list of 50 numbers], nextword: [another list], so on...}\n",
    "    \n",
    "#create an empty embedding matrix holding the embedding lookup table (vocab size, embed dim)\n",
    "#we use random.normal instead of zeros, to keep the embedding matrix arbitrary in case word vectors don't exist....\n",
    "embeddings_matrix = np.asarray(np.random.normal(0, 0.9, (parser.n_tokens, 50)), dtype='float32')\n",
    "\n",
    "for token in parser.tok2id:\n",
    "        i = parser.tok2id[token]\n",
    "        if token in word_vectors:\n",
    "            embeddings_matrix[i] = word_vectors[token]\n",
    "        elif token.lower() in word_vectors:\n",
    "            embeddings_matrix[i] = word_vectors[token.lower()]\n",
    "print(\"Embedding matrix shape (vocab, emb size): \", embeddings_matrix.shape)\n",
    "print(\"took {:.2f} seconds\".format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# Let's declare some list of word that we want to plot\n",
    "cos_test_word_list = ['employer', 'worker', 'company', 'organization', 'manufacturing',\n",
    "'people', 'mountain', 'resigning', 'man']\n",
    "\n",
    "cos_test_preemb_list = [word_vectors[word] for word in cos_test_word_list]\n",
    "# Noted: there is no 26 in this test because the pre-embeded that we use do not have this word\n",
    "print(len(cos_test_preemb_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.164262</td>\n",
       "      <td>-2.416502</td>\n",
       "      <td>employer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.325450</td>\n",
       "      <td>-2.584370</td>\n",
       "      <td>worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.218122</td>\n",
       "      <td>-2.420501</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.328885</td>\n",
       "      <td>-2.013297</td>\n",
       "      <td>organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.671002</td>\n",
       "      <td>-2.247920</td>\n",
       "      <td>manufacturing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y           word\n",
       "0  2.164262 -2.416502       employer\n",
       "1  0.325450 -2.584370         worker\n",
       "2 -1.218122 -2.420501        company\n",
       "3 -0.328885 -2.013297   organization\n",
       "4  1.671002 -2.247920  manufacturing"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "reduced = pca.fit(cos_test_preemb_list).transform(cos_test_preemb_list)\n",
    "reduced = pd.DataFrame(reduced,columns=['X','Y'])\n",
    "reduced['word'] = cos_test_word_list #adding columns\n",
    "reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(x=reduced['X'],y=reduced['Y'])\n",
    "plt.title('Pre_embed similarity')\n",
    "for idx, value in reduced.iterrows():\n",
    "    plt.annotate(reduced['word'][idx],value[:-1])\n",
    "\n",
    "path = '/root/projects/NLP/Assignment/26_Jan_Depedency_Parser/output/Pre_embed/Pre_embed_fig.png'\n",
    "plt.savefig(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency comparision\n",
    "Now, Let's try to compare the dependency of our neural network with spacy!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare some sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading data\n"
     ]
    }
   ],
   "source": [
    "# Let's reload data because we want it's to be word\n",
    "_, _, test_set = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's be picky, just get some short word\n",
    "test_sentence = [sent for sent in test_set if len(sent['word']) < 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's handpick some sentences for our model\n",
    "test_sentence_1 = test_sentence[19] # ['the', 'centers', 'normally', 'are', 'closed', 'through', 'the', 'weekend', '.']\n",
    "test_sentence_2 = test_sentence[20] # ['the', 'accord', 'expired', 'yesterday', '.']\n",
    "test_sentence_3 = test_sentence[21] # ['martinair', 'holland', 'is', 'based', 'in', 'amsterdam', '.']\n",
    "\n",
    "# To make it's the same format as we did above\n",
    "test_our_model_sent = list()\n",
    "test_our_model_sent.append(test_sentence_1)\n",
    "test_our_model_sent.append(test_sentence_2)\n",
    "test_our_model_sent.append(test_sentence_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'centers', 'normally', 'are', 'closed', 'through', 'the', 'weekend', '.']\n",
      "['the', 'accord', 'expired', 'yesterday', '.']\n",
      "['martinair', 'holland', 'is', 'based', 'in', 'amsterdam', '.']\n"
     ]
    }
   ],
   "source": [
    "# Let's print to check to be sure!\n",
    "for sent in test_our_model_sent:\n",
    "    print(sent['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5156, 85, 5154, 3381, 116, 356, 379, 85, 4139, 87]\n",
      "[5156, 85, 5154, 5154, 351, 87]\n",
      "[5156, 5154, 5154, 102, 330, 91, 3516, 87]\n"
     ]
    }
   ],
   "source": [
    "# Now, Numericalize its!\n",
    "test_our_model_sent = parser.numericalize(test_our_model_sent)\n",
    "\n",
    "for sent in test_our_model_sent:\n",
    "    print(sent['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sentence for spacy\n",
    "test_spacy_sent1 = 'the centers normally are closed through the weekend .'\n",
    "test_spacy_sent2 = 'the accord expired yesterday .'\n",
    "test_spacy_sent3 = 'martinair holland is based in amsterdam .'\n",
    "\n",
    "test_spacy_sent = test_spacy_sent1,  test_spacy_sent2,  test_spacy_sent3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"f529c24ca9bc4a9f97caa1e8d367b2fb-0\" class=\"displacy\" width=\"1625\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">centers</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">normally</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">are</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">closed</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">through</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">weekend</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PUNCT</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f529c24ca9bc4a9f97caa1e8d367b2fb-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f529c24ca9bc4a9f97caa1e8d367b2fb-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f529c24ca9bc4a9f97caa1e8d367b2fb-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 750.0,2.0 750.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f529c24ca9bc4a9f97caa1e8d367b2fb-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f529c24ca9bc4a9f97caa1e8d367b2fb-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f529c24ca9bc4a9f97caa1e8d367b2fb-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f529c24ca9bc4a9f97caa1e8d367b2fb-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f529c24ca9bc4a9f97caa1e8d367b2fb-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f529c24ca9bc4a9f97caa1e8d367b2fb-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f529c24ca9bc4a9f97caa1e8d367b2fb-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f529c24ca9bc4a9f97caa1e8d367b2fb-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f529c24ca9bc4a9f97caa1e8d367b2fb-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f529c24ca9bc4a9f97caa1e8d367b2fb-0-6\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f529c24ca9bc4a9f97caa1e8d367b2fb-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f529c24ca9bc4a9f97caa1e8d367b2fb-0-7\" stroke-width=\"2px\" d=\"M770,264.5 C770,2.0 1450.0,2.0 1450.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f529c24ca9bc4a9f97caa1e8d367b2fb-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,266.5 L1458.0,254.5 1442.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"eef669c6e0cc4ddaac2bb91c747113a4-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">accord</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">expired</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">yesterday</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PUNCT</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eef669c6e0cc4ddaac2bb91c747113a4-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eef669c6e0cc4ddaac2bb91c747113a4-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eef669c6e0cc4ddaac2bb91c747113a4-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eef669c6e0cc4ddaac2bb91c747113a4-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eef669c6e0cc4ddaac2bb91c747113a4-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eef669c6e0cc4ddaac2bb91c747113a4-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eef669c6e0cc4ddaac2bb91c747113a4-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eef669c6e0cc4ddaac2bb91c747113a4-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"fbdbf027ae9e4a0690df7bea5a0fe72a-0\" class=\"displacy\" width=\"1275\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">martinair</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">holland</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">based</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">amsterdam</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PUNCT</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fbdbf027ae9e4a0690df7bea5a0fe72a-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fbdbf027ae9e4a0690df7bea5a0fe72a-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fbdbf027ae9e4a0690df7bea5a0fe72a-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fbdbf027ae9e4a0690df7bea5a0fe72a-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fbdbf027ae9e4a0690df7bea5a0fe72a-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fbdbf027ae9e4a0690df7bea5a0fe72a-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fbdbf027ae9e4a0690df7bea5a0fe72a-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fbdbf027ae9e4a0690df7bea5a0fe72a-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fbdbf027ae9e4a0690df7bea5a0fe72a-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fbdbf027ae9e4a0690df7bea5a0fe72a-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fbdbf027ae9e4a0690df7bea5a0fe72a-0-5\" stroke-width=\"2px\" d=\"M595,177.0 C595,2.0 1100.0,2.0 1100.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fbdbf027ae9e4a0690df7bea5a0fe72a-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,179.0 L1108.0,167.0 1092.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#we eventually gonna make the dependency\n",
    "#so maybe we can cheat a little bit, and see the answer\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy #displacy is for visualization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "for sent in test_spacy_sent:\n",
    "    doc = nlp(sent)\n",
    "    options = {\"collapse_punct\": False}\n",
    "    displacy.render(doc, options = options, style=\"dep\", jupyter=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParserModel(\n",
       "  (pretrained_embeddings): Embedding(5157, 50)\n",
       "  (embed_to_hidden): Linear(in_features=2400, out_features=400, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (hidden_to_logits): Linear(in_features=400, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get parser\n",
    "#parser = Parser(train_set)\n",
    "# Load model\n",
    "model = ParserModel(embeddings_matrix)\n",
    "model.eval()\n",
    "\n",
    "parser.model = model\n",
    "weight_path = '/root/projects/NLP/Assignment/26_Jan_Depedency_Parser/output/20230128_180042_All_features/model.weights'\n",
    "parser.model.load_state_dict(torch.load(weight_path))\n",
    "parser.model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 9478.65it/s]             \n"
     ]
    }
   ],
   "source": [
    "# Let get the dependencies\n",
    "UAS, dependencies = parser.parse(test_our_model_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2, 1), (5, 4), (5, 3), (5, 2), (8, 7), (8, 6), (5, 8), (5, 9), (0, 5)],\n",
       " [(2, 1), (4, 3), (2, 4), (2, 5), (0, 2)],\n",
       " [(2, 1), (4, 3), (4, 2), (6, 5), (4, 6), (4, 7), (0, 4)]]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../26_Jan_Depedency_Parser/dep_fig/test1.jpg\">\n",
    "<img src=\"../26_Jan_Depedency_Parser/dep_fig/test2.jpg\">\n",
    "<img src=\"../26_Jan_Depedency_Parser/dep_fig/test3.jpg\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "## Ablation studies\n",
    "    In our model, we have mainly 3 features (word, pos, dep). I tried accroding to the assignment instruction and the results are displayed below.\n",
    "\n",
    "| Case |     Features    | Dev UAS | Test UAS |\n",
    "|------|:---------------:|---------|:--------:|\n",
    "| 1    | Words, POS, DEP | 75.42   | 76.18    |\n",
    "| 2    | Words, DEP      | 66.22   | 67.38    |\n",
    "| 3    | Words, POS      | 75.62   | 77.68    |\n",
    "\n",
    "    Surprisingly, case1 and case3 produce the same results (more or less). I think this can indicate that the dependencies feature is not significant or maybe worse. If we remove this feature maybe accruacy might be improved (need furthur study). In contrast POS is very significant in this case by cutting this feature. The accruacy drop around 8~10%.\n",
    "\n",
    "## Embedding Comparision\n",
    "    In this session I tried to compare the pre-embedding that we got from Chaky, Glove embedding that I train by my self for 5,000 epochs and Word2Vec Skipgrams (As it's the simplest form of usable nn.Embedding that I known).\n",
    "\n",
    "\n",
    "<img src=\"/root/projects/NLP/Assignment/26_Jan_Depedency_Parser/output/Pre_embed/Pre_embed_fig.png\">  \n",
    "<img src=\"/root/projects/NLP/Assignment/26_Jan_Depedency_Parser/output/Glove_weight/Glove_fig.png\">  \n",
    "<img src=\"/root/projects/NLP/Assignment/26_Jan_Depedency_Parser/output/Skipgram_weight/Skipgrams_fig.png\">  \n",
    "\n",
    "    The pre_embed embedding work very well. It known that 'organization', 'worker', 'company', 'manufacturing' and 'employer' words are close together but it's a bit weird that 'resigning' and 'people' have a little distance.\n",
    "\n",
    "    Surprisingly, glove embedding that train for 5,000 epochs can capture the relation between 'organization', 'man'\n",
    "    and 'resignning'; 'people' and 'worker'. \n",
    "    Words 'company' and 'employer' are little close. I think this model is very powerful I think if we train more the accuracy can be improve.\n",
    "\n",
    "    Lastly, Skipgrams that I trained for 5,000 epochs. Everything in the skipgrams seem to have the same distance. At least 'company' and 'man' \n",
    "    are a bit close. This indicate that word2vec with skipgrams is not good at capturing words relation.\n",
    "\n",
    "## Sentence comparision\n",
    "    I handpicked 3 sentences to compare. All of them do not have the same dependency but 80% similar. From my observation I think spaCy model is better. At the example 1 (pic 1 from above) our model see that 'weekend' depends on 'through' but spaCy predicted the opposite. All of the root are the same which is a good sign. I think the model that we used are around 60 ~ 70 % as powerful as spaCy.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
